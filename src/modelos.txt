Usar esses modelos com CLS e mean_pooling:

https://huggingface.co/rufimelo/Legal-BERTimbau-sts-large-ma-v3
https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2
https://huggingface.co/neuralmind/bert-base-portuguese-cased
https://huggingface.co/stjiris/bert-large-portuguese-cased-legal-mlm-sts-v1.0
https://huggingface.co/stjiris/bert-large-portuguese-cased-legal-mlm-nli-sts-v1
https://huggingface.co/Luciano/bert-base-portuguese-cased-finetuned-tcu-acordaos


https://platform.openai.com/docs/guides/embeddings/embedding-models
https://platform.openai.com/docs/guides/embeddings

Possibilidades:
    Pedir para IA generativa gerar palavras chaves e indexar essas palavra no lugar do enunciado e buscar com BM25 ou embeddings.
    Fazer fine tunning do modelo, usando normas por exemplo. (llama 3b x bert)
    Reranking, Muito trabalhoso.
    
    
##########################################################################################################################################    
BERT -> fine-tuning do modelo
cabeça de classificação

Treino:
 
[CLS] ENUNCIADO [SEP] queries positivas [SEP]   -> Classe +
[CLS] ENUNCIADO [SEP] queries nada a ver [SEP]  -> Classe -
 
Modelo que recebe um enunciado e um conjunto de queries e vai tentar associar a que classe pertence, se a + ou -
Pesquisa de primeiro estágio retornando, por exemplo, 500 resultados. E aí passa para o segundo estágio de reranking que vai passar todos esses 500 resultados e a query no modelo. E aí ele vai reordenar de acordo com a probabilidade associada a classe +
 
Tem a opção de pular o fine-tuning e usar um modelo pronto (exemplo PTT5-BASE). Fazer o fine-tuning com um modelo que já dá resultados próximos ao BM25 vale a pena.

Para fazer o fine-tuning vamos precisar de dados de treinamento. Não podemos usar nada do qrels como base, senão misturaremos treino/teste. Uma alternativa é pegar os resultados de sinônimos que o Llama3 já extraiu nos testes e usar como exemplos de queries.

https://github.com/carisio/IA368-DD_deep_learning_busca/blob/main/2%20-%20classificador%20binario%20-%20reranking%20com%20minilm/notebook/Aula2_classificador_binario_mini_bert.ipynb

########################################

Termos large 100%|██████████| 1/1 [01:06<00:00, 66.04s/it]
Documentos large 100%|██████████| 32/32 [2:17:35<00:00, 257.99s/it]  
Termos small 100%|██████████| 1/1 [01:16<00:00, 76.85s/it]
Documentos small 100%|██████████| 32/32 [1:31:37<00:00, 171.79s/it]
Termos ada 100%|██████████| 1/1 [00:45<00:00, 45.03s/it]
Documentos ada 100%|██████████| 32/32 [1:14:55<00:00, 140.48s/it]

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caderno de teste - Métricas\n",
    "\n",
    "A primeira parte do caderno é um conjunto de testes com a biblioteca evaluate/trec_eval.\n",
    "\n",
    "Em seguida, o caderno contém uma implementação própria para o cálculo das métricas precisão (P@k), recall (R@k), MRR (MRR@k) e nDCG (nDCG@k). A ideia é ter um código um pouco mais legível, mesmo que ineficiente.\n",
    "\n",
    "Fontes:\n",
    "\n",
    "- https://huggingface.co/spaces/evaluate-metric/trec_eval\n",
    "\n",
    "- https://github.com/joaopalotti/trectools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste 1 - Execução simples testando uma query\n",
    "\n",
    "Vamos supor que o qrel da query 0 indica 3 documentos, doc_1, doc_2 e doc_3, cujas relevâncias são 3, 2, 1.\n",
    "\n",
    "O sistema de busca retornou, nessa ordem, doc_2, doc_1, doc_10, doc_11, doc_12:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.8174935137996165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caris\\anaconda3\\Lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "trec_eval = load(\"trec_eval\")\n",
    " \n",
    "qrel = {\n",
    "    \"query\": [0, 0, 0],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    \"rel\": [3, 2, 1]\n",
    "    }\n",
    "run = {\n",
    "    \"query\": [0, 0, 0, 0, 0], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\", \"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\", \"doc_10\", \"doc_11\", \"doc_12\"], # DOCUMENT_ID\n",
    "    \"rank\": [1, 2, 3, 3, 4], # RANKING DO DOCUMENTO\n",
    "    \"score\": [2, 3, 0, 0, 0], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"test\", \"test\", \"test\", \"test\", \"test\"] # SISTEMA\n",
    "}\n",
    " \n",
    " \n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print(results['P@5'])\n",
    "print(results['NDCG@5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos ver o que ocorre se tirarmos os três documentos não relevantes (não pode mudar nada):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.8174935137996165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caris\\anaconda3\\Lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0, 0, 0],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    \"rel\": [3, 2, 1]\n",
    "    }\n",
    "run = {\n",
    "    \"query\": [0, 0], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1], # RANKING DO DOCUMENTO\n",
    "    \"score\": [1.5, 1.2], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"test\", \"test\"] # SISTEMA\n",
    "}\n",
    " \n",
    " \n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print(results['P@5'])\n",
    "print(results['NDCG@5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checando o efeito do score no qrels (só pode mudar o ndcg, mas a precisão tem que continuar a mesma):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.777975983841851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caris\\anaconda3\\Lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0, 0, 0],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    \"rel\": [10, 9, 8]\n",
    "    }\n",
    "run = {\n",
    "    \"query\": [0, 0], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1], # RANKING DO DOCUMENTO\n",
    "    \"score\": [1.5, 1.2], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"test\", \"test\"] # SISTEMA\n",
    "}\n",
    " \n",
    " \n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print(results['P@5'])\n",
    "print(results['NDCG@5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos alterar novamente o score no qrel, mas para 30, 20, 10 (mantém a mesma proporção que 3, 2, 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caris\\anaconda3\\Lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.8174935137996167\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0, 0, 0],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    \"rel\": [30, 20, 10]\n",
    "    }\n",
    "run = {\n",
    "    \"query\": [0, 0], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1], # RANKING DO DOCUMENTO\n",
    "    \"score\": [1.5, 1.2], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"test\", \"test\"] # SISTEMA\n",
    "}\n",
    " \n",
    " \n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print(results['P@5'])\n",
    "print(results['NDCG@5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver se o score no run faz algum efeito:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caris\\anaconda3\\Lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.8174935137996165\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0, 0, 0],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    \"rel\": [3, 2, 1]\n",
    "    }\n",
    "run = {\n",
    "    \"query\": [0, 0], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1], # RANKING DO DOCUMENTO\n",
    "    \"score\": [0, 1000], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"test\", \"test\"] # SISTEMA\n",
    "}\n",
    " \n",
    " \n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print(results['P@5'])\n",
    "print(results['NDCG@5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As conclusões aqui:\n",
    "\n",
    "- O score no qrel fazem diferença pro nDCG. Uma relação de 2/1 no score do qrel equivale a uma relação de 6/2. A relação entre os scores no qrel parece ser multiplicativa.\n",
    "\n",
    "- O score no run parece não fazer diferença para o nDCG. Mesmo mudando a ordem (colocando um score mais alto para quem está mais atrás no ranking) não faz diferença nos valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste 2 - Execução testando uma query e dois sistemas\n",
    "\n",
    "Vamos supor que o qrel da query 0 indica 3 documentos, doc_1, doc_2 e doc_3, cujas relevâncias são 3, 2, 1.\n",
    "\n",
    "O sistema 1 retornou, nessa ordem, doc_2, doc_1.\n",
    "\n",
    "O sistema 2 retornou apenas doc_3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.9224945116765986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caris\\anaconda3\\Lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0, 0, 0],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    \"rel\": [3, 2, 1]\n",
    "    }\n",
    "run = {\n",
    "    \"query\": [0, 0, 0], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\", \"doc_3\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1, 0], # RANKING DO DOCUMENTO\n",
    "    \"score\": [2, 1, 2], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"sistema1\", \"sistema1\", \"sistema2\"] # SISTEMA\n",
    "}\n",
    " \n",
    " \n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print(results['P@5'])\n",
    "print(results['NDCG@5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado não é o que queremos e dá pra ver isso na precisão.\n",
    "\n",
    "Estou interpretando \"system\" como um sistema, então quero o resultado por sistema. \n",
    "\n",
    "O que eu esperava aqui é ter uma precisão/ndcg para o sistema 1 e uma precisão/ndcg para o sistema 2. Vamos tentar separar o run em dois, run_sistema_1 e run_sistema_2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essa abordagem não dá certo\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0, 0, 0],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    \"rel\": [3, 2, 1]\n",
    "    }\n",
    "run_sistema_1 = {\n",
    "    \"query\": [0, 0], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1], # RANKING DO DOCUMENTO\n",
    "    \"score\": [2, 1], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"sistema1\", \"sistema1\"] # SISTEMA\n",
    "}\n",
    " \n",
    "run_sistema_2 = {\n",
    "    \"query\": [0], # QUERY ID\n",
    "    \"q0\": [\"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_3\"], # DOCUMENT_ID\n",
    "    \"rank\": [0], # RANKING DO DOCUMENTO\n",
    "    \"score\": [2], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"sistema2\"] # SISTEMA\n",
    "}\n",
    "\n",
    "try:\n",
    "    results = trec_eval.compute(predictions=[run_sistema_1, run_sistema_2], references=[qrel])\n",
    "    print(results['P@5'])\n",
    "    print(results['NDCG@5'])\n",
    "except:\n",
    "    print('Essa abordagem não dá certo')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O jeito parece ser separar e rodar duas vezes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caris\\anaconda3\\Lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n",
      "C:\\Users\\caris\\anaconda3\\Lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.8174935137996165\n",
      "******************************\n",
      "0.2\n",
      "0.21000199575396408\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0, 0, 0],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    \"rel\": [3, 2, 1]\n",
    "    }\n",
    "run_sistema_1 = {\n",
    "    \"query\": [0, 0], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1], # RANKING DO DOCUMENTO\n",
    "    \"score\": [2, 1], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"sistema1\", \"sistema1\"] # SISTEMA\n",
    "}\n",
    " \n",
    "run_sistema_2 = {\n",
    "    \"query\": [0], # QUERY ID\n",
    "    \"q0\": [\"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_3\"], # DOCUMENT_ID\n",
    "    \"rank\": [0], # RANKING DO DOCUMENTO\n",
    "    \"score\": [2], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"sistema2\"] # SISTEMA\n",
    "}\n",
    "\n",
    "results_sistema_1 = trec_eval.compute(predictions=[run_sistema_1], references=[qrel])\n",
    "results_sistema_2 = trec_eval.compute(predictions=[run_sistema_2], references=[qrel])\n",
    "print(results_sistema_1['P@5'])\n",
    "print(results_sistema_1['NDCG@5'])\n",
    "print('*'*30)\n",
    "print(results_sistema_2['P@5'])\n",
    "print(results_sistema_2['NDCG@5'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste 3: agregando queries diferentes para um sistema\n",
    "\n",
    "Agora que sabemos como a ferramenta trata sistemas diferentes (é necessário executar separadamente), vamos ver como é o tratamento com mais de uma query. Vamos testar 3 queries:\n",
    "\n",
    "O qrel de cada query está assim:\n",
    "\n",
    "- query 0\n",
    "    - docs: doc_1, doc_2, doc_3\n",
    "    - relevância: 3, 2, 1\n",
    "\n",
    "- query 1\n",
    "    - docs: doc_1, doc_5, doc_6\n",
    "    - relevância: 3, 2, 1\n",
    "\n",
    "- query 2\n",
    "    - docs: doc_3\n",
    "    - relevância: 3\n",
    "\n",
    "O sistema de busca retornou:\n",
    "\n",
    "- query 0:\n",
    "    - docs: doc_1, doc_2 (P@5 = 2/5 = 0.4)\n",
    "- query 1:\n",
    "    - docs: doc_5 (P@5 = 1/5 = 0.2)\n",
    "- query 2:\n",
    "    - docs: não retornou nada (P@5 = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a query 2 não retornou nada, vou fazer o primeiro teste sem passar ela:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30000000000000004\n",
      "0.6187487526537724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caris\\anaconda3\\Lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0, 0, 0, 1, 1, 1, 2],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\", \"q0\", \"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\", \"doc_1\", \"doc_5\", \"doc_6\", \"doc_3\"],\n",
    "    \"rel\": [3, 2, 1, 3, 2, 1, 3]\n",
    "    }\n",
    "run = {\n",
    "    \"query\": [0, 0, 1], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\", \"doc_5\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1, 0], # RANKING DO DOCUMENTO\n",
    "    \"score\": [2, 1, 2], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"test\", \"test\", \"test\"] # SISTEMA\n",
    "}\n",
    " \n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print(results['P@5'])\n",
    "print(results['NDCG@5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A média dos P@5 deve ser de (0.4 + 0.2 + 0)/3 = 0.2.\n",
    "\n",
    "Como não passamos a query 2, ele desconsiderou-a da métrica. Assim, mesmo que não tenha resultados, é necessário informá-la de alguma forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20000000000000004\n",
      "0.4124991684358483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caris\\anaconda3\\Lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0, 0, 0, 1, 1, 1, 2],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\", \"q0\", \"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\", \"doc_1\", \"doc_5\", \"doc_6\", \"doc_3\"],\n",
    "    \"rel\": [3, 2, 1, 3, 2, 1, 3]\n",
    "    }\n",
    "run = {\n",
    "    \"query\": [0, 0, 1, 2], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\", \"doc_5\", \"\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1, 0, -1], # RANKING DO DOCUMENTO\n",
    "    \"score\": [2, 1, 2, -1], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"test\", \"test\", \"test\", \"test\"] # SISTEMA\n",
    "}\n",
    " \n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print(results['P@5'])\n",
    "print(results['NDCG@5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passando vazio no docid e -1 no rank/score funcionou. O mesmo ocorre passando alguma string inexistente no docid e qualquer outro número no rank/score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caris\\anaconda3\\Lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20000000000000004\n",
      "0.4124991684358483\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0, 0, 0, 1, 1, 1, 2],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\", \"q0\", \"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\", \"doc_1\", \"doc_5\", \"doc_6\", \"doc_3\"],\n",
    "    \"rel\": [3, 2, 1, 3, 2, 1, 3]\n",
    "    }\n",
    "run = {\n",
    "    \"query\": [0, 0, 1, 2], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\", \"doc_5\", \"XXXXXXX\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1, 0, 0], # RANKING DO DOCUMENTO\n",
    "    \"score\": [2, 1, 2, 0], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"test\", \"test\", \"test\", \"test\"] # SISTEMA\n",
    "}\n",
    " \n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print(results['P@5'])\n",
    "print(results['NDCG@5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste cálculo manual do nDCG para apenas uma query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 1 3.0\n",
      "B 2 4.416508275000202\n",
      "C 3 0.0\n",
      "D 4 0.43067655807339306\n",
      "E 5 1.1605584217036249\n",
      "\n",
      "\n",
      "B 1 7.0\n",
      "A 2 1.8927892607143721\n",
      "E 3 1.5\n",
      "D 4 0.43067655807339306\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8322420383257692"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Vamos considerar que a entrada é no seguinte formato:\n",
    "# doc_retornados = [\"doc_a\", \"doc_b\", \"doc_c\" etc]. A posição indica a ordem\n",
    "# Para facilitar, vamos considerar que doc_relevantes é um dict assim:\n",
    "# {\"doc_x\": score, \"doc_y\": score etc}\n",
    "def dcg(doc_retornados, doc_relevantes, k=None, debug=True, aproximacao_trec_eval=False):\n",
    "    dcg = 0\n",
    "    doc_retornados = doc_retornados if k is None else doc_retornados[:k]\n",
    "    for rank, doc_id in enumerate(doc_retornados, 1):\n",
    "        # Relevância do documento\n",
    "        rel = doc_relevantes.get(doc_id, 0)\n",
    "        # Cálculo do ganho. Aproximação trec_eval usa diretamente a relevância\n",
    "        gain = (2**(rel) - 1) if not aproximacao_trec_eval else rel\n",
    "        dcg_i = gain/(math.log(rank + 1, 2))\n",
    "        dcg += dcg_i\n",
    "        if debug:\n",
    "            print(doc_id, rank, dcg_i)\n",
    "\n",
    "    if debug:\n",
    "        print('\\n')\n",
    "    return dcg\n",
    "\n",
    "def idcg(doc_retornados, doc_relevantes, k=None, debug=True, aproximacao_trec_eval=False):\n",
    "    # Cria uma lista de tuplas (doc_id, relevância, posição original na lista de retornados)\n",
    "    # para todos os documentos relevantes\n",
    "    # A posição original só é usada para desempate, portanto, ela segue a ordem de doc_retornados\n",
    "    docs_com_relevancia = [\n",
    "        (doc, \n",
    "        doc_relevantes.get(doc, 0), # Nem precisava de get, pois certamente existe\n",
    "        doc_retornados.index(doc) if doc in doc_retornados else len(doc_retornados))\n",
    "        for doc in doc_relevantes.keys()\n",
    "    ]\n",
    "\n",
    "    # Ordena os documentos primeiro pela relevância (decrescente) e depois pela posição original (crescente)\n",
    "    # Isso garante que, em caso de empate na relevância, o documento que apareceu primeiro em doc_retornados ganhe\n",
    "    docs_ordenados = sorted(docs_com_relevancia, key=lambda x: (-x[1], x[2]))\n",
    "\n",
    "    # Extrai apenas os doc_ids da lista ordenada\n",
    "    doc_retornados_ideal = [doc[0] for doc in docs_ordenados]\n",
    "\n",
    "    return dcg(doc_retornados_ideal, doc_relevantes, k, debug, aproximacao_trec_eval)\n",
    "\n",
    "def ndcg(doc_retornados, doc_relevantes, k=None, debug=True, aproximacao_trec_eval=False):\n",
    "    return dcg(doc_retornados, doc_relevantes, k, debug, aproximacao_trec_eval) / idcg(doc_retornados, doc_relevantes, k, debug, aproximacao_trec_eval)\n",
    "\n",
    "doc_retornados = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "doc_relevantes = {\"A\": 2, \"B\": 3, \"D\": 1, \"E\": 2}\n",
    "ndcg(doc_retornados, doc_relevantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos testar essa função com os resultados obtidos do trec_eval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7895959410076381\n",
      "0.8174935137996168\n",
      "Esperado: 0.8174\n"
     ]
    }
   ],
   "source": [
    "doc_retornados = [\"doc_2\", \"doc_1\", \"doc_10\", \"doc_11\", \"doc_12\"]\n",
    "doc_relevantes = {\"doc_1\": 3, \"doc_2\": 2, \"doc_3\": 1}\n",
    "print(ndcg(doc_retornados, doc_relevantes, k=None, debug=False, aproximacao_trec_eval=False))\n",
    "print(ndcg(doc_retornados, doc_relevantes, k=None, debug=False, aproximacao_trec_eval=True))\n",
    "print('Esperado: 0.8174')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10646464774659968\n",
      "0.2100019957539641\n",
      "Esperado: 0.210\n"
     ]
    }
   ],
   "source": [
    "doc_retornados = [\"doc_3\"]\n",
    "doc_relevantes = {\"doc_1\": 3, \"doc_2\": 2, \"doc_3\": 1}\n",
    "print(ndcg(doc_retornados, doc_relevantes, k=None, debug=False, aproximacao_trec_eval=False))\n",
    "print(ndcg(doc_retornados, doc_relevantes, k=None, debug=False, aproximacao_trec_eval=True))\n",
    "print('Esperado: 0.210')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando cálculo manual do nDCG@k:\n",
    "\n",
    "Vamos considerar que o qrels tem mais do que 5 resultados, apenas para checarmos como fica o nDCG@5 e o nDCG@10.\n",
    "\n",
    "Vamos considerar também que a lista de resultados tem mais do que 5 elementos.\n",
    "\n",
    "Nesse caso, devem dar resultados diferentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caris\\anaconda3\\Lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TREC_EVAL:\n",
      "nDCG@5: 0.42010951172205624\n",
      "nDCG@10: 0.40014926254662797\n",
      "IMPLEMENTAÇÃO:\n",
      "nDCG@5: 0.4201095117220563\n",
      "nDCG@10: 0.40014926254662797\n"
     ]
    }
   ],
   "source": [
    "\n",
    "qrel = {\n",
    "    \"query\": [0, 0, 0, 0, 0, 0],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\", \"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\", \"doc_4\", \"doc_5\", \"doc_6\"],\n",
    "    \"rel\": [3, 2, 1, 3, 2, 1]\n",
    "    }\n",
    "\n",
    "\n",
    "run = {\n",
    "    \"query\": [0, 0, 0, 0, 0], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\", \"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_1\", \"A\", \"B\", \"C\", \"D\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1, 2, 3, 4], # RANKING DO DOCUMENTO\n",
    "    \"score\": [6, 5, 4, 3, 2], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"test\", \"test\", \"test\", \"test\", \"test\"] # SISTEMA\n",
    "}\n",
    " \n",
    " \n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print('TREC_EVAL:')\n",
    "print(f\"nDCG@5: {results['NDCG@5']}\")\n",
    "print(f\"nDCG@10: {results['NDCG@10']}\")\n",
    "\n",
    "\n",
    "doc_retornados = [\"doc_1\", \"A\", \"B\", \"C\", \"D\"]\n",
    "doc_relevantes = {\"doc_1\": 3, \"doc_2\": 2, \"doc_3\": 1, \"doc_4\": 3, \"doc_5\": 2, \"doc_6\": 1}\n",
    "print('IMPLEMENTAÇÃO:')\n",
    "print(f\"nDCG@5: {ndcg(doc_retornados, doc_relevantes, k=5, debug=False, aproximacao_trec_eval=True)}\")\n",
    "print(f\"nDCG@10: {ndcg(doc_retornados, doc_relevantes, k=10, debug=False, aproximacao_trec_eval=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TREC_EVAL:\n",
      "nDCG@5: 0.4742830263739263\n",
      "nDCG@10: 0.4517488843896262\n",
      "IMPLEMENTAÇÃO:\n",
      "nDCG@5: 0.47428302637392633\n",
      "nDCG@10: 0.45174888438962624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caris\\anaconda3\\Lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "qrel = {\n",
    "    \"query\": [0, 0, 0, 0, 0, 0],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\", \"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\", \"doc_4\", \"doc_5\", \"doc_6\"],\n",
    "    \"rel\": [3, 2, 1, 3, 2, 1]\n",
    "    }\n",
    "\n",
    "\n",
    "run = {\n",
    "    \"query\": [0, 0, 0, 0, 0], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\", \"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_1\", \"A\", \"B\", \"C\", \"doc_3\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1, 2, 3, 4], # RANKING DO DOCUMENTO\n",
    "    \"score\": [6, 5, 4, 3, 2], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"test\", \"test\", \"test\", \"test\", \"test\"] # SISTEMA\n",
    "}\n",
    " \n",
    " \n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print('TREC_EVAL:')\n",
    "print(f\"nDCG@5: {results['NDCG@5']}\")\n",
    "print(f\"nDCG@10: {results['NDCG@10']}\")\n",
    "\n",
    "\n",
    "doc_retornados = [\"doc_1\", \"A\", \"B\", \"C\", \"doc_3\"]\n",
    "doc_relevantes = {\"doc_1\": 3, \"doc_2\": 2, \"doc_3\": 1, \"doc_4\": 3, \"doc_5\": 2, \"doc_6\": 1}\n",
    "print('IMPLEMENTAÇÃO:')\n",
    "print(f\"nDCG@5: {ndcg(doc_retornados, doc_relevantes, k=5, debug=False, aproximacao_trec_eval=True)}\")\n",
    "print(f\"nDCG@10: {ndcg(doc_retornados, doc_relevantes, k=10, debug=False, aproximacao_trec_eval=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação de uma lib para facilitar o cálculo das métricas\n",
    "\n",
    "A ideia aqui é implementar um conjunto de funções que receberá dataframes Pandas para o resultado e para o qrels e retornará um conjunto de métricas (MRR, Precision, Recall, nDCG).\n",
    "\n",
    "Como é para uso pessoal e em poucos testes, minha inteção é prezar pela legibilidade em detrimento da eficiência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def precisao_recall(docs_retornados, docs_relevantes, k=None):\n",
    "    \"\"\"\n",
    "        Dado um conjunto de documentos retornados e de documentos relevantes,\n",
    "        calcula a precisão e o recall em k para uma query.\n",
    "\n",
    "        docs_retornados -- Objeto Series contendo os documentos retornados ordenados\n",
    "        docs_relevantes -- Objeto Series contendo os documentos relevantes\n",
    "        k -- No cálculo da precisão e recall, indica até que posição dos documentos\n",
    "                retornados deve ser considerada.\n",
    "\n",
    "        Se k = None, toda a lista de documentos retornados é considerada. Se k != None,\n",
    "        considera apenas os k'éssimos primeiros documentos retornados.\n",
    "        Para o cálculo da precisão, se k = None, considera no denominador o total de documentos retornados\n",
    "    \"\"\"\n",
    "    if k is None:\n",
    "        k = len(docs_retornados)\n",
    "    docs_retornados_em_k = docs_retornados[:k]\n",
    "    docs_retornados_em_k_relevantes = set(docs_retornados_em_k) & set(docs_relevantes)\n",
    "\n",
    "    precisao = len(docs_retornados_em_k_relevantes)/max(k, 1)\n",
    "    recall = len(docs_retornados_em_k_relevantes)/len(docs_relevantes)\n",
    "\n",
    "    return precisao, recall\n",
    "\n",
    "def mrr(docs_retornados, docs_relevantes, k=None):\n",
    "    \"\"\"\n",
    "        Calcula o MRR@k (Mean Reciprocal Rank) para uma query.\n",
    "\n",
    "        docs_retornados -- Objeto Series contendo os documentos retornados ordenados\n",
    "        docs_relevantes -- Objeto Series contendo os documentos relevantes\n",
    "        k -- Indica até que posição dos documentos retornados deve ser considerada.\n",
    "    \"\"\"\n",
    "    if k is None:\n",
    "        k = len(docs_retornados)\n",
    "\n",
    "    mrr_score = 0.0\n",
    "    set_docs_relevantes = set(docs_relevantes)\n",
    "    for i in range(min(k, len(docs_retornados))):\n",
    "        if docs_retornados.iloc[i] in set_docs_relevantes:\n",
    "            mrr_score = 1.0 / (i+1) # Soma com 1 pois a posição começa em 1 e i começa em 0.\n",
    "            break\n",
    "    return mrr_score\n",
    "\n",
    "def dcg(doc_retornados, doc_relevantes, k=None, debug=True, aproximacao_trec_eval=False):\n",
    "    \"\"\"\n",
    "        Calcula DCG@k para uma query.\n",
    "\n",
    "        doc_retornados -- É uma lista de keys de documentos. A posição do documento na lista\n",
    "            indica a ordem\n",
    "        docs_relevantes -- É um dict cuja chave é a key e um documento relevante e o valor\n",
    "            é o seu score\n",
    "        k -- Indica até que posição dos documentos retornados deve ser considerada.\n",
    "        debug -- Indica se é pra imprimir o cálculo intermediário\n",
    "        aproximacao_trec_eval -- Se True, usa a relevância como Linear. Se False, usa\n",
    "            como 2^(rel)\n",
    "    \"\"\"\n",
    "    dcg = 0\n",
    "    doc_retornados = doc_retornados if k is None else doc_retornados[:k]\n",
    "    for rank, doc_id in enumerate(doc_retornados, 1):\n",
    "        # Relevância do documento\n",
    "        rel = doc_relevantes.get(doc_id, 0)\n",
    "        # Cálculo do ganho. Aproximação trec_eval usa diretamente a relevância\n",
    "        gain = (2**(rel) - 1) if not aproximacao_trec_eval else rel\n",
    "        dcg_i = gain/(math.log(rank + 1, 2))\n",
    "        dcg += dcg_i\n",
    "        if debug:\n",
    "            print(doc_id, rank, dcg_i)\n",
    "\n",
    "    if debug:\n",
    "        print('\\n')\n",
    "    return dcg\n",
    "\n",
    "def idcg(doc_retornados, doc_relevantes, k=None, debug=True, aproximacao_trec_eval=False):\n",
    "    \"\"\"\n",
    "        Calcula iDCG@k para uma query.\n",
    "\n",
    "        doc_retornados -- É uma lista de keys de documentos. A posição do documento na lista\n",
    "            indica a ordem\n",
    "        docs_relevantes -- É um dict cuja chave é a key e um documento relevante e o valor\n",
    "            é o seu score\n",
    "        k -- Indica até que posição dos documentos retornados deve ser considerada.\n",
    "        debug -- Indica se é pra imprimir o cálculo intermediário\n",
    "        aproximacao_trec_eval -- Se True, usa a relevância como Linear. Se False, usa\n",
    "            como 2^(rel)\n",
    "    \"\"\"\n",
    "    # Cria uma lista de tuplas (doc_id, relevância, posição original na lista de retornados)\n",
    "    # para todos os documentos relevantes\n",
    "    # A posição original só é usada para desempate, portanto, ela segue a ordem de doc_retornados\n",
    "    docs_com_relevancia = [\n",
    "        (doc, \n",
    "        doc_relevantes.get(doc, 0), # Nem precisava de get, pois certamente existe\n",
    "        doc_retornados.index(doc) if doc in doc_retornados else len(doc_retornados))\n",
    "        for doc in doc_relevantes.keys()\n",
    "    ]\n",
    "\n",
    "    # Ordena os documentos primeiro pela relevância (decrescente) e depois pela posição original (crescente)\n",
    "    # Isso garante que, em caso de empate na relevância, o documento que apareceu primeiro em doc_retornados ganhe\n",
    "    docs_ordenados = sorted(docs_com_relevancia, key=lambda x: (-x[1], x[2]))\n",
    "\n",
    "    # Extrai apenas os doc_ids da lista ordenada\n",
    "    doc_retornados_ideal = [doc[0] for doc in docs_ordenados]\n",
    "\n",
    "    return dcg(doc_retornados_ideal, doc_relevantes, k, debug, aproximacao_trec_eval)\n",
    "\n",
    "def ndcg(resultado_pesquisa, qrels, col_resultado_doc_key, col_qrels_doc_key, col_qrels_score, k=None, debug=True, aproximacao_trec_eval=False):\n",
    "    \"\"\"\n",
    "        Calcula o nDCG@k para uma query\n",
    "\n",
    "        resultado_pesquisa -- DataFrame Pandas com o resultado da pesquisa. Considera que\n",
    "            o DataFrame está ordenado de acordo com os documentos retornados\n",
    "        qrels -- DataFrame Pandas com o qrels\n",
    "\n",
    "        col_resultado_doc_key -- indica a KEY do documento retornado.\n",
    "        col_qrels_doc_key -- indica a KEY de um documento associado a query.\n",
    "        col_qrels_score -- indica a relevância do documento para aquela query. Quanto maior, mais relevante.\n",
    "\n",
    "        k -- Indica até que posição dos documentos retornados deve ser considerada.\n",
    "        debug -- Indica se é pra imprimir o cálculo intermediário\n",
    "        aproximacao_trec_eval -- Se True, usa a relevância como Linear. Se False, usa\n",
    "            como 2^(rel)\n",
    "    \"\"\"\n",
    "    # Converte os pandas para lista de doc_retornados e dict de doc_relevantes por score:\n",
    "    doc_retornados = resultado_pesquisa[col_resultado_doc_key].tolist()\n",
    "    doc_relevantes = dict(zip(qrels[col_qrels_doc_key], qrels[col_qrels_score]))\n",
    "\n",
    "    return dcg(doc_retornados, doc_relevantes, k, debug, aproximacao_trec_eval) / idcg(doc_retornados, doc_relevantes, k, debug, aproximacao_trec_eval)\n",
    "\n",
    "def metricas(resultado_pesquisa, qrels, \n",
    "             col_resultado_query_key=\"QUERY_KEY\",\n",
    "             col_resultado_doc_key=\"DOC_KEY\",\n",
    "             col_resultado_rank=\"RANK\",\n",
    "             col_qrels_query_key=\"QUERY_KEY\",\n",
    "             col_qrels_doc_key=\"DOC_KEY\",\n",
    "             col_qrels_score=\"SCORE\",\n",
    "             k=[5, 10, 50], debug=False, aproximacao_trec_eval=False):\n",
    "    \"\"\"\n",
    "        Calcula um conjunto de métricas para um resultado de pesquisa e um conjunto qrels.\n",
    "        resultado_pesquisa -- DataFrame Pandas contendo o resultado das pesquisas.\n",
    "        qrels -- DataFrame Pandas contendo o qrels\n",
    "\n",
    "        Os parâmetros col_resultado_xxxx referem-se a nomes de colunas no DataFrame resultado_pesquisa:\n",
    "\n",
    "        col_resultado_query_key -- indica a KEY da query.\n",
    "        col_resultado_doc_key -- indica a KEY do documento retornado.\n",
    "        col_resultado_rank -- indica a posição do documento retornado.\n",
    "\n",
    "        Os parâmetros col_qrels_xxxx referem-se a nomes de colunas no DataFrame qrels:\n",
    "\n",
    "        col_qrels_query_key -- indica a KEY da query que será testada.\n",
    "        col_qrels_doc_key -- indica a KEY de um documento associado a query.\n",
    "        col_qrels_score -- indica a relevância do documento para aquela query. Quanto maior, mais relevante.\n",
    "    \"\"\"\n",
    "    # Remove do qrels os resultados cujo score é 0\n",
    "    qrels = qrels[qrels[col_qrels_score] > 0]\n",
    "\n",
    "    # Extrai as queries que devem ser analisadas. Se tiver query no resultado que não \n",
    "    # está no qrels, ela não será avaliada.\n",
    "    query_keys = qrels.QUERY_KEY.unique()\n",
    "\n",
    "    precisao_em_k = {valor_k: [0]*len(query_keys) for valor_k in k}\n",
    "    recall_em_k = {valor_k: [0]*len(query_keys) for valor_k in k}\n",
    "    mrr_em_k = {valor_k: [0]*len(query_keys) for valor_k in k}\n",
    "    ndcg_em_k = {valor_k: [0]*len(query_keys) for valor_k in k}\n",
    "\n",
    "    for i_q_key, q_key in enumerate(query_keys):\n",
    "        # Extrai o resultado e o qrels para a query que irá ser analisada\n",
    "        resultado_para_query = resultado_pesquisa[resultado_pesquisa[col_resultado_query_key] == q_key]\n",
    "        qrels_para_query = qrels[qrels[col_qrels_query_key] == q_key]\n",
    "        \n",
    "        # Pega os docs retornados (ordenados de acordo com a posição deles na pesquisa, em ordem crescente - Rank 1 para cima)\n",
    "        # e os docs relevantes.\n",
    "        resultado_para_query = resultado_para_query.sort_values(by=col_resultado_rank)\n",
    "        docs_retornados = resultado_para_query[col_resultado_doc_key]\n",
    "        docs_relevantes = qrels_para_query[col_qrels_doc_key]\n",
    "\n",
    "        for valor_k in k:\n",
    "            p_em_k, r_em_k = precisao_recall(docs_retornados, docs_relevantes, valor_k)\n",
    "            precisao_em_k[valor_k][i_q_key] = p_em_k\n",
    "            recall_em_k[valor_k][i_q_key] = r_em_k\n",
    "            mrr_em_k[valor_k][i_q_key] = mrr(docs_retornados, docs_relevantes, valor_k)\n",
    "            ndcg_em_k[valor_k][i_q_key] = ndcg(resultado_para_query, qrels_para_query, col_resultado_doc_key, col_qrels_doc_key, col_qrels_score, valor_k, debug, aproximacao_trec_eval)\n",
    "\n",
    "    pd_metricas = pd.DataFrame({'QUERY_KEY': query_keys})\n",
    "\n",
    "    # Insere as métricas na ordem: precisão, recall, MRR, nDCG:\n",
    "    for valor_k in k:\n",
    "        pd_metricas[f'P@{valor_k}'] = precisao_em_k[valor_k]\n",
    "    for valor_k in k:\n",
    "        pd_metricas[f'R@{valor_k}'] = recall_em_k[valor_k]\n",
    "    for valor_k in k:\n",
    "        pd_metricas[f'MRR@{valor_k}'] = mrr_em_k[valor_k]\n",
    "    for valor_k in k:\n",
    "        pd_metricas[f'nDCG@{valor_k}'] = ndcg_em_k[valor_k]\n",
    "\n",
    "    return pd_metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evitar replicação do código acima nos outros notebooks, ele foi exportado para o arquivo metricas.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes com dados fictícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refaz os testes anteriores. Para isso, separa cada teste como um query_key diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUERY_KEY</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>P@50</th>\n",
       "      <th>R@5</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@50</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@10</th>\n",
       "      <th>MRR@50</th>\n",
       "      <th>nDCG@5</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>nDCG@50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.817494</td>\n",
       "      <td>0.817494</td>\n",
       "      <td>0.817494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777976</td>\n",
       "      <td>0.777976</td>\n",
       "      <td>0.777976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.817494</td>\n",
       "      <td>0.817494</td>\n",
       "      <td>0.817494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.210002</td>\n",
       "      <td>0.210002</td>\n",
       "      <td>0.210002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QUERY_KEY  P@5  P@10  P@50       R@5      R@10      R@50  MRR@5  MRR@10  \\\n",
       "0          0  0.4   0.2  0.04  0.666667  0.666667  0.666667    1.0     1.0   \n",
       "1          1  0.4   0.2  0.04  0.666667  0.666667  0.666667    1.0     1.0   \n",
       "2          2  0.4   0.2  0.04  0.666667  0.666667  0.666667    1.0     1.0   \n",
       "3          3  0.2   0.1  0.02  0.333333  0.333333  0.333333    1.0     1.0   \n",
       "\n",
       "   MRR@50    nDCG@5   nDCG@10   nDCG@50  \n",
       "0     1.0  0.817494  0.817494  0.817494  \n",
       "1     1.0  0.777976  0.777976  0.777976  \n",
       "2     1.0  0.817494  0.817494  0.817494  \n",
       "3     1.0  0.210002  0.210002  0.210002  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DataFrame qrels\n",
    "QRELS_QUERY_KEY = [0, 0, 0,\n",
    "                   1, 1, 1,\n",
    "                   2, 2, 2,\n",
    "                   3, 3, 3]\n",
    "QRELS_DOC_KEY = [\"doc_1\", \"doc_2\", \"doc_3\",\n",
    "                 \"doc_1\", \"doc_2\", \"doc_3\",\n",
    "                 \"doc_1\", \"doc_2\", \"doc_3\",\n",
    "                 \"doc_1\", \"doc_2\", \"doc_3\"]\n",
    "QRELS_SCORE = [3, 2, 1,\n",
    "               10, 9, 8,\n",
    "               3, 2, 1,\n",
    "               3, 2, 1]\n",
    "\n",
    "# DataFrame resultado\n",
    "RESULTADO_QUERY_KEY = [0, 0, 0, 0, 0,\n",
    "                       1, 1,\n",
    "                       2, 2,\n",
    "                       3]\n",
    "RESULTADO_DOC_KEY = [\"doc_2\", \"doc_1\", \"doc_10\", \"doc_11\", \"doc_12\",\n",
    "                     \"doc_2\", \"doc_1\",\n",
    "                     \"doc_2\", \"doc_1\",\n",
    "                     \"doc_3\"]\n",
    "RESULTADO_RANK = [1, 2, 3, 4, 5,\n",
    "                  1, 2,\n",
    "                  1, 2,\n",
    "                  1]\n",
    "\n",
    "# DataFrames\n",
    "resultado = pd.DataFrame({\n",
    "        \"QUERY_KEY\": RESULTADO_QUERY_KEY,\n",
    "        \"DOC_KEY\": RESULTADO_DOC_KEY,\n",
    "        \"RANK\": RESULTADO_RANK\n",
    "})\n",
    "qrels = pd.DataFrame({\n",
    "        \"QUERY_KEY\": QRELS_QUERY_KEY,\n",
    "        \"DOC_KEY\": QRELS_DOC_KEY,\n",
    "        \"SCORE\": QRELS_SCORE\n",
    "})\n",
    "\n",
    "# Métricas\n",
    "pd_metricas = metricas(resultado, qrels, aproximacao_trec_eval=True)\n",
    "\n",
    "display(pd_metricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes com os dados da pesquisa de jurisprudência selecionada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PASTA_DADOS = './dados/'\n",
    "PASTA_JURIS_TCU = f'{PASTA_DADOS}outputs/1_tratamento_juris_tcu/'\n",
    "PASTA_RESULTADO_PESQUISA_SOLR = f'{PASTA_DADOS}outputs/2_pesquisa_queries_na_base_atual/'\n",
    "\n",
    "qrels = pd.read_csv(f'{PASTA_JURIS_TCU}qrel_tratado.csv', sep='|')\n",
    "resultado_pesq_solr = pd.read_csv(f'{PASTA_RESULTADO_PESQUISA_SOLR}resultado_solr_pesquisa_original.csv', sep='|')\n",
    "\n",
    "# Seleciona só o resultado do \\select\n",
    "resultado_select = resultado_pesq_solr[resultado_pesq_solr.ENGINE == 'SOLR_PESQUISA_ORIGINAL_selectSwanSynonym']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa a implementação de métricas que foi exportada para o arquivo metricas.py\n",
    "from metricas import metricas\n",
    "\n",
    "pd_metricas = metricas(resultado_select, qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUERY_KEY</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>P@20</th>\n",
       "      <th>P@50</th>\n",
       "      <th>R@5</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@20</th>\n",
       "      <th>R@50</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@10</th>\n",
       "      <th>MRR@20</th>\n",
       "      <th>MRR@50</th>\n",
       "      <th>nDCG@5</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>nDCG@20</th>\n",
       "      <th>nDCG@50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.50000</td>\n",
       "      <td>0.288000</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.131600</td>\n",
       "      <td>0.115506</td>\n",
       "      <td>0.212030</td>\n",
       "      <td>0.361585</td>\n",
       "      <td>0.534756</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>0.396278</td>\n",
       "      <td>0.404327</td>\n",
       "      <td>0.405359</td>\n",
       "      <td>0.254451</td>\n",
       "      <td>0.265024</td>\n",
       "      <td>0.348817</td>\n",
       "      <td>0.436694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.57738</td>\n",
       "      <td>0.318568</td>\n",
       "      <td>0.23819</td>\n",
       "      <td>0.138785</td>\n",
       "      <td>0.061024</td>\n",
       "      <td>0.126254</td>\n",
       "      <td>0.188635</td>\n",
       "      <td>0.247196</td>\n",
       "      <td>0.271167</td>\n",
       "      <td>0.404922</td>\n",
       "      <td>0.385263</td>\n",
       "      <td>0.377376</td>\n",
       "      <td>0.376281</td>\n",
       "      <td>0.307321</td>\n",
       "      <td>0.264734</td>\n",
       "      <td>0.256080</td>\n",
       "      <td>0.237769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.135714</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064506</td>\n",
       "      <td>0.142892</td>\n",
       "      <td>0.258370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.50000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.154762</td>\n",
       "      <td>0.374126</td>\n",
       "      <td>0.535897</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.138637</td>\n",
       "      <td>0.199914</td>\n",
       "      <td>0.300741</td>\n",
       "      <td>0.431461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.75000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.426083</td>\n",
       "      <td>0.420779</td>\n",
       "      <td>0.483425</td>\n",
       "      <td>0.563506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917352</td>\n",
       "      <td>0.949243</td>\n",
       "      <td>0.949243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       QUERY_KEY        P@5      P@10       P@20       P@50        R@5  \\\n",
       "count   50.00000  50.000000  50.00000  50.000000  50.000000  50.000000   \n",
       "mean    25.50000   0.288000   0.26000   0.218000   0.131600   0.115506   \n",
       "std     14.57738   0.318568   0.23819   0.138785   0.061024   0.126254   \n",
       "min      1.00000   0.000000   0.00000   0.000000   0.000000   0.000000   \n",
       "25%     13.25000   0.000000   0.10000   0.100000   0.100000   0.000000   \n",
       "50%     25.50000   0.200000   0.20000   0.225000   0.130000   0.076923   \n",
       "75%     37.75000   0.550000   0.40000   0.300000   0.180000   0.200000   \n",
       "max     50.00000   1.000000   0.90000   0.500000   0.220000   0.384615   \n",
       "\n",
       "            R@10       R@20       R@50      MRR@5     MRR@10     MRR@20  \\\n",
       "count  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000   \n",
       "mean    0.212030   0.361585   0.534756   0.372000   0.396278   0.404327   \n",
       "std     0.188635   0.247196   0.271167   0.404922   0.385263   0.377376   \n",
       "min     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "25%     0.071429   0.135714   0.357143   0.000000   0.111111   0.111111   \n",
       "50%     0.154762   0.374126   0.535897   0.250000   0.250000   0.250000   \n",
       "75%     0.333333   0.525000   0.750000   0.875000   0.875000   0.875000   \n",
       "max     0.642857   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "          MRR@50     nDCG@5    nDCG@10    nDCG@20    nDCG@50  \n",
       "count  50.000000  50.000000  50.000000  50.000000  50.000000  \n",
       "mean    0.405359   0.254451   0.265024   0.348817   0.436694  \n",
       "std     0.376281   0.307321   0.264734   0.256080   0.237769  \n",
       "min     0.000000   0.000000   0.000000   0.000000   0.000000  \n",
       "25%     0.111111   0.000000   0.064506   0.142892   0.258370  \n",
       "50%     0.250000   0.138637   0.199914   0.300741   0.431461  \n",
       "75%     0.875000   0.426083   0.420779   0.483425   0.563506  \n",
       "max     1.000000   1.000000   0.917352   0.949243   0.949243  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_metricas[0:50].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUERY_KEY</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>P@20</th>\n",
       "      <th>P@50</th>\n",
       "      <th>R@5</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@20</th>\n",
       "      <th>R@50</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@10</th>\n",
       "      <th>MRR@20</th>\n",
       "      <th>MRR@50</th>\n",
       "      <th>nDCG@5</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>nDCG@20</th>\n",
       "      <th>nDCG@50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75.50000</td>\n",
       "      <td>0.456000</td>\n",
       "      <td>0.28800</td>\n",
       "      <td>0.157000</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.189168</td>\n",
       "      <td>0.239564</td>\n",
       "      <td>0.261051</td>\n",
       "      <td>0.270384</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.590248</td>\n",
       "      <td>0.510355</td>\n",
       "      <td>0.507727</td>\n",
       "      <td>0.512356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.57738</td>\n",
       "      <td>0.280058</td>\n",
       "      <td>0.22825</td>\n",
       "      <td>0.131324</td>\n",
       "      <td>0.056649</td>\n",
       "      <td>0.119936</td>\n",
       "      <td>0.197816</td>\n",
       "      <td>0.225615</td>\n",
       "      <td>0.247692</td>\n",
       "      <td>0.283223</td>\n",
       "      <td>0.283223</td>\n",
       "      <td>0.283223</td>\n",
       "      <td>0.283223</td>\n",
       "      <td>0.237041</td>\n",
       "      <td>0.203683</td>\n",
       "      <td>0.199326</td>\n",
       "      <td>0.203514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>51.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>63.25000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.085227</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491832</td>\n",
       "      <td>0.414196</td>\n",
       "      <td>0.417795</td>\n",
       "      <td>0.417795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>75.50000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.160256</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.588925</td>\n",
       "      <td>0.510112</td>\n",
       "      <td>0.496489</td>\n",
       "      <td>0.497628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>87.75000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.267045</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.371795</td>\n",
       "      <td>0.371795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.753477</td>\n",
       "      <td>0.651250</td>\n",
       "      <td>0.656560</td>\n",
       "      <td>0.656560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.939877</td>\n",
       "      <td>0.931057</td>\n",
       "      <td>0.931057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       QUERY_KEY        P@5      P@10       P@20       P@50        R@5  \\\n",
       "count   50.00000  50.000000  50.00000  50.000000  50.000000  50.000000   \n",
       "mean    75.50000   0.456000   0.28800   0.157000   0.064800   0.189168   \n",
       "std     14.57738   0.280058   0.22825   0.131324   0.056649   0.119936   \n",
       "min     51.00000   0.000000   0.00000   0.000000   0.000000   0.000000   \n",
       "25%     63.25000   0.200000   0.10000   0.050000   0.020000   0.083333   \n",
       "50%     75.50000   0.400000   0.20000   0.100000   0.040000   0.160256   \n",
       "75%     87.75000   0.600000   0.40000   0.200000   0.080000   0.267045   \n",
       "max    100.00000   1.000000   0.90000   0.500000   0.200000   0.500000   \n",
       "\n",
       "            R@10       R@20       R@50      MRR@5     MRR@10     MRR@20  \\\n",
       "count  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000   \n",
       "mean    0.239564   0.261051   0.270384   0.866667   0.866667   0.866667   \n",
       "std     0.197816   0.225615   0.247692   0.283223   0.283223   0.283223   \n",
       "min     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "25%     0.085227   0.090909   0.090909   1.000000   1.000000   1.000000   \n",
       "50%     0.166667   0.166667   0.166667   1.000000   1.000000   1.000000   \n",
       "75%     0.326923   0.371795   0.371795   1.000000   1.000000   1.000000   \n",
       "max     0.900000   0.900000   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "          MRR@50     nDCG@5    nDCG@10    nDCG@20    nDCG@50  \n",
       "count  50.000000  50.000000  50.000000  50.000000  50.000000  \n",
       "mean    0.866667   0.590248   0.510355   0.507727   0.512356  \n",
       "std     0.283223   0.237041   0.203683   0.199326   0.203514  \n",
       "min     0.000000   0.000000   0.000000   0.000000   0.000000  \n",
       "25%     1.000000   0.491832   0.414196   0.417795   0.417795  \n",
       "50%     1.000000   0.588925   0.510112   0.496489   0.497628  \n",
       "75%     1.000000   0.753477   0.651250   0.656560   0.656560  \n",
       "max     1.000000   1.000000   0.939877   0.931057   0.931057  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_metricas[50:100].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUERY_KEY</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>P@20</th>\n",
       "      <th>P@50</th>\n",
       "      <th>R@5</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@20</th>\n",
       "      <th>R@50</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@10</th>\n",
       "      <th>MRR@20</th>\n",
       "      <th>MRR@50</th>\n",
       "      <th>nDCG@5</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>nDCG@20</th>\n",
       "      <th>nDCG@50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>125.50000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.01800</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.016394</td>\n",
       "      <td>0.016394</td>\n",
       "      <td>0.016394</td>\n",
       "      <td>0.016394</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.052941</td>\n",
       "      <td>0.041068</td>\n",
       "      <td>0.040646</td>\n",
       "      <td>0.040646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.57738</td>\n",
       "      <td>0.125779</td>\n",
       "      <td>0.06289</td>\n",
       "      <td>0.031445</td>\n",
       "      <td>0.012578</td>\n",
       "      <td>0.057238</td>\n",
       "      <td>0.057238</td>\n",
       "      <td>0.057238</td>\n",
       "      <td>0.057238</td>\n",
       "      <td>0.307889</td>\n",
       "      <td>0.307889</td>\n",
       "      <td>0.307889</td>\n",
       "      <td>0.307889</td>\n",
       "      <td>0.161611</td>\n",
       "      <td>0.124877</td>\n",
       "      <td>0.123674</td>\n",
       "      <td>0.123674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>101.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>113.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>125.50000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>137.75000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>150.00000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.868795</td>\n",
       "      <td>0.634412</td>\n",
       "      <td>0.628212</td>\n",
       "      <td>0.628212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       QUERY_KEY        P@5      P@10       P@20       P@50        R@5  \\\n",
       "count   50.00000  50.000000  50.00000  50.000000  50.000000  50.000000   \n",
       "mean   125.50000   0.036000   0.01800   0.009000   0.003600   0.016394   \n",
       "std     14.57738   0.125779   0.06289   0.031445   0.012578   0.057238   \n",
       "min    101.00000   0.000000   0.00000   0.000000   0.000000   0.000000   \n",
       "25%    113.25000   0.000000   0.00000   0.000000   0.000000   0.000000   \n",
       "50%    125.50000   0.000000   0.00000   0.000000   0.000000   0.000000   \n",
       "75%    137.75000   0.000000   0.00000   0.000000   0.000000   0.000000   \n",
       "max    150.00000   0.800000   0.40000   0.200000   0.080000   0.363636   \n",
       "\n",
       "            R@10       R@20       R@50      MRR@5     MRR@10     MRR@20  \\\n",
       "count  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000   \n",
       "mean    0.016394   0.016394   0.016394   0.110000   0.110000   0.110000   \n",
       "std     0.057238   0.057238   0.057238   0.307889   0.307889   0.307889   \n",
       "min     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "25%     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "50%     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "75%     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "max     0.363636   0.363636   0.363636   1.000000   1.000000   1.000000   \n",
       "\n",
       "          MRR@50     nDCG@5    nDCG@10    nDCG@20    nDCG@50  \n",
       "count  50.000000  50.000000  50.000000  50.000000  50.000000  \n",
       "mean    0.110000   0.052941   0.041068   0.040646   0.040646  \n",
       "std     0.307889   0.161611   0.124877   0.123674   0.123674  \n",
       "min     0.000000   0.000000   0.000000   0.000000   0.000000  \n",
       "25%     0.000000   0.000000   0.000000   0.000000   0.000000  \n",
       "50%     0.000000   0.000000   0.000000   0.000000   0.000000  \n",
       "75%     0.000000   0.000000   0.000000   0.000000   0.000000  \n",
       "max     1.000000   0.868795   0.634412   0.628212   0.628212  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_metricas[100:150].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compara se as métricas calculadas estão batendo com as do TRECEVAL\n",
    "\n",
    "Testa com as 10 primeiras queries (que existem).\n",
    "\n",
    "Se tiver qrels e resultados, o resultado quase sempre bate. Os únicos casos em que não batem são quando há empate no score. A minha implementação confia no RANKING dos resultados na hora de calcular a precisão. O TREC_EVAL parece que reordena baseado no score e, quando dá empate, um documento relevante pode acabar entrando ou saindo da busca.\n",
    "\n",
    "Isso ocorre na QUERY_KEY == 14 por exemplo. Assim, se rodar o código abaixo com testar_com_primeiras_k_queries <= 13, o resultado bate nas casas decimais. Se rodar com testar_com_primeiras_k_queries >= 14, esse fato acaba ocorrendo no cálculo de P@10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado TREC_EVAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caris\\anaconda3\\Lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25800000000000006\n",
      "0.21799999999999997\n",
      "0.2656040382169855\n",
      "0.3415420926151102\n",
      "\n",
      "Resultado Implementado\n",
      "0.26\n",
      "0.21799999999999997\n",
      "0.2656040382169855\n",
      "0.3415420926151102\n"
     ]
    }
   ],
   "source": [
    "testar_com_primeiras_k_queries = 50\n",
    "qrels_filtrado = qrels[qrels.QUERY_KEY <= testar_com_primeiras_k_queries]\n",
    "resultado_filtrado = resultado_select[resultado_select.QUERY_KEY <= testar_com_primeiras_k_queries]\n",
    "\n",
    "qrel = {\n",
    "    \"query\": list(qrels_filtrado.QUERY_KEY),\n",
    "    \"q0\": [\"q0\"] * len(qrels_filtrado),\n",
    "    \"docid\": list(qrels_filtrado.DOC_KEY),\n",
    "    \"rel\": list(qrels_filtrado.SCORE)\n",
    "    }\n",
    "run = {\n",
    "    \"query\": list(resultado_filtrado.QUERY_KEY), # QUERY ID\n",
    "    \"q0\": [\"q0\"] * len(resultado_filtrado), # LITERAL q0\n",
    "    \"docid\": list(resultado_filtrado.DOC_KEY), # DOCUMENT_ID\n",
    "    \"rank\": list(resultado_filtrado.RANK), # RANKING DO DOCUMENTO\n",
    "    \"score\": list(resultado_filtrado.SCORE), # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"test\"] * len(resultado_filtrado) # SISTEMA\n",
    "}\n",
    " \n",
    "print('Resultado TREC_EVAL')\n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print(results['P@10'])\n",
    "print(results['P@20'])\n",
    "print(results['NDCG@10'])\n",
    "print(results['NDCG@20'])\n",
    "\n",
    "print('\\nResultado Implementado')\n",
    "pd_metricas = metricas(resultado_select, qrels, aproximacao_trec_eval=True)\n",
    "resumo_metricas = pd_metricas[pd_metricas.QUERY_KEY <= testar_com_primeiras_k_queries].describe()\n",
    "print(resumo_metricas['P@10']['mean'])\n",
    "print(resumo_metricas['P@20']['mean'])\n",
    "print(resumo_metricas['nDCG@10']['mean'])\n",
    "print(resumo_metricas['nDCG@20']['mean'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

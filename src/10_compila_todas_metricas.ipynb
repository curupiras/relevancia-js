{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "610656ac-55ab-408e-b8c7-9fdd96be1ee9",
   "metadata": {},
   "source": [
    "# Caderno 10 - Compila todas as métricas.\n",
    "\n",
    "As tabelas são as combinações dos conjuntos de queries (3 conjuntos) e k = [5, 10, 20]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2e5ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Modelos\n",
    "#MODELOS = ['rufimelo/Legal-BERTimbau-sts-large-ma-v3',\n",
    "#           'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
    "#           'neuralmind/bert-large-portuguese-cased']\n",
    "\n",
    "MODELOS = ['rufimelo/Legal-BERTimbau-sts-large-ma-v3',\n",
    "           'sentence-transformers/paraphrase-multilingual-mpnet-base-v2']\n",
    "\n",
    "# Seleciona o tipo de camada oculta\n",
    "TIPOS_CAMADA_OCULTA = ['mean_hidden_state',\n",
    "                       'cls_hidden_state']\n",
    "\n",
    "PASTA_DADOS = './dados/'\n",
    "PASTA_RESULTADO_CADERNO = f'{PASTA_DADOS}outputs/10_compila_todas_metricas/'\n",
    "ARQUIVO_METRICAS_BM25 = f'{PASTA_DADOS}outputs/4_metricas_bm25_padrao/metricas_bm25.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6ec69d",
   "metadata": {},
   "source": [
    "## 1. Carrega dados de jurisprudência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f395fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from metricas import metricas\n",
    "\n",
    "# A pasta dos JURIS aqui não é a pasta original, e sim o resultado do caderno 1 (os documentos já estão filtrados)\n",
    "PASTA_JURIS_TCU = f'{PASTA_DADOS}outputs/1_tratamento_juris_tcu/'\n",
    "\n",
    "# Carrega os arquivos \n",
    "def carrega_juris_tcu():\n",
    "    doc1 = pd.read_csv(f'{PASTA_JURIS_TCU}doc_tratado_parte_1.csv', sep='|')\n",
    "    doc2 = pd.read_csv(f'{PASTA_JURIS_TCU}doc_tratado_parte_2.csv', sep='|')\n",
    "    doc3 = pd.read_csv(f'{PASTA_JURIS_TCU}doc_tratado_parte_3.csv', sep='|')\n",
    "    doc4 = pd.read_csv(f'{PASTA_JURIS_TCU}doc_tratado_parte_4.csv', sep='|')\n",
    "    doc = pd.concat([doc1, doc2, doc3, doc4], ignore_index=True)\n",
    "    query = pd.read_csv(f'{PASTA_JURIS_TCU}query_tratado.csv', sep='|')\n",
    "    qrel = pd.read_csv(f'{PASTA_JURIS_TCU}qrel_tratado.csv', sep='|')\n",
    "\n",
    "    return doc, query, qrel\n",
    "\n",
    "docs, queries, qrels = carrega_juris_tcu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce73ad20",
   "metadata": {},
   "source": [
    "## 2. Extrai as métricas\n",
    "\n",
    "Carrega a lista dos resultados das queries realizadas no banco vetorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a03bb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Carrega métricas do bm25_padrao\n",
    "mapa_metricas = {}\n",
    "\n",
    "with open(ARQUIVO_METRICAS_BM25, 'rb') as arquivo:\n",
    "    metricas_bm25_padrao = pickle.load(arquivo)\n",
    "    \n",
    "mapa_metricas['bm25_padrao'] = metricas_bm25_padrao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbc9bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para encontrar a correspondência entre keys\n",
    "def find_key(doc_key, docs):\n",
    "    matches = docs[docs['KEY'].str.contains(doc_key, na=False)]\n",
    "    if not matches.empty:\n",
    "        return matches.iloc[0]['KEY']\n",
    "    return doc_key\n",
    "\n",
    "# Função que constroi dataframe de resultados no formato esperado pela função de métricas\n",
    "def processa_resultado(I, docs):\n",
    "    col_resultado_query_key = []\n",
    "    col_resultado_doc_key = []\n",
    "    col_resultado_rank = []\n",
    "\n",
    "    # Preenchendo as listas\n",
    "    for query_idx in range(len(I)):\n",
    "        for rank_idx in range(len(I[0])):\n",
    "            col_resultado_query_key.append(query_idx + 1)\n",
    "            col_resultado_doc_key.append(I[query_idx, rank_idx])\n",
    "            col_resultado_rank.append(rank_idx + 1)\n",
    "\n",
    "    df_resultados = pd.DataFrame({\n",
    "        \"QUERY_KEY\": col_resultado_query_key,\n",
    "        \"DOC_KEY\": col_resultado_doc_key,\n",
    "        \"RANK\": col_resultado_rank,\n",
    "    })\n",
    "\n",
    "    df_resultados['DOC_KEY'] = df_resultados['DOC_KEY'].astype(str)\n",
    "    df_resultados['DOC_KEY'] = df_resultados['DOC_KEY'].apply(lambda x: find_key(x, docs))\n",
    "    \n",
    "    return df_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e8a0e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando MODELOS:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Processando rufimelo/Legal-BERTimbau-sts-large-ma-v3:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Processando MODELOS:   0%|          | 0/2 [00:00<?, ?it/s]                                 \u001b[A\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './dados/outputs/8_armazena_dados_em_banco_vetorial/Legal-BERTimbau-sts-large-ma-v3/Legal-BERTimbau-sts-large-ma-v3_mean_resultado_query.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m tipo \u001b[38;5;241m=\u001b[39m tipo_camada_oculta\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     12\u001b[0m arquivo_resultado_busca \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpasta_resultado_busca\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcaminho_modelo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtipo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_resultado_query.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(arquivo_resultado_busca, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m arquivo:\n\u001b[0;32m     15\u001b[0m     I \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(arquivo)\n\u001b[0;32m     17\u001b[0m df_resultados \u001b[38;5;241m=\u001b[39m processa_resultado(I, docs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dados/outputs/8_armazena_dados_em_banco_vetorial/Legal-BERTimbau-sts-large-ma-v3/Legal-BERTimbau-sts-large-ma-v3_mean_resultado_query.pickle'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from metricas import metricas\n",
    "from tqdm import tqdm\n",
    "\n",
    "for modelo in tqdm(MODELOS, desc='Processando MODELOS'):\n",
    "    \n",
    "    caminho_modelo = modelo.split(\"/\")[-1]\n",
    "    pasta_resultado_busca = f'{PASTA_DADOS}outputs/8_armazena_dados_em_banco_vetorial/{caminho_modelo}/'\n",
    "    \n",
    "    for tipo_camada_oculta in tqdm(TIPOS_CAMADA_OCULTA, desc=f'Processando {modelo}', leave=False):\n",
    "        tipo = tipo_camada_oculta.split('_')[0]\n",
    "        arquivo_resultado_busca = f'{pasta_resultado_busca}{caminho_modelo}_{tipo_camada_oculta}_resultado_query.pickle'\n",
    "        \n",
    "        with open(arquivo_resultado_busca, 'rb') as arquivo:\n",
    "            I = pickle.load(arquivo)\n",
    "            \n",
    "        df_resultados = processa_resultado(I, docs)\n",
    "        metrica_calculada = metricas(df_resultados, qrels, aproximacao_trec_eval=True)\n",
    "        mapa_metricas[f'{caminho_modelo}_{tipo_camada_oculta}'] = metrica_calculada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa_metricas['paraphrase-multilingual-mpnet-base-v2_mean_hidden_state']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64580529-173b-446a-a160-bde8c1069ddf",
   "metadata": {},
   "source": [
    "## 4. Exibe as métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69991d0-efb7-4069-8c9e-4196391f7a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime as métricas para o conjunto de queries 1 (0:50), 2 (100:150), ou 3 (100:150) \n",
    "# e para um determinado k (foi gerado para k = 5, 10, 20 e 50.\n",
    "\n",
    "def compara_metricas(con_query, k):\n",
    "    # Acumula as métricas\n",
    "    precisao = []\n",
    "    recall = []\n",
    "    mrr = []\n",
    "    ndcg = []\n",
    "\n",
    "    for nome in mapa_metricas.keys():\n",
    "        estatisticas = mapa_metricas[nome][50*(con_query-1):50*(con_query)].describe()\n",
    "        precisao.append(estatisticas.loc['mean', f'P@{k}'])\n",
    "        recall.append(estatisticas.loc['mean', f'R@{k}'])\n",
    "        mrr.append(estatisticas.loc['mean', f'MRR@{k}'])\n",
    "        ndcg.append(estatisticas.loc['mean', f'nDCG@{k}'])\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"Modelo\": mapa_metricas.keys(),\n",
    "        f\"P@{k}\": precisao,\n",
    "        f\"R@{k}\": recall,\n",
    "        f\"MRR@{k}\": mrr,\n",
    "        f\"nDCG@{k}\": ndcg\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def compara_metricas_todas_queries(k):\n",
    "    # Acumula as métricas\n",
    "    precisao = []\n",
    "    recall = []\n",
    "    mrr = []\n",
    "    ndcg = []\n",
    "\n",
    "    for nome in mapa_metricas.keys():\n",
    "        estatisticas = mapa_metricas[nome].describe()\n",
    "        precisao.append(estatisticas.loc['mean', f'P@{k}'])\n",
    "        recall.append(estatisticas.loc['mean', f'R@{k}'])\n",
    "        mrr.append(estatisticas.loc['mean', f'MRR@{k}'])\n",
    "        ndcg.append(estatisticas.loc['mean', f'nDCG@{k}'])\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"Modelo\": mapa_metricas.keys(),\n",
    "        f\"P@{k}\": precisao,\n",
    "        f\"R@{k}\": recall,\n",
    "        f\"MRR@{k}\": mrr,\n",
    "        f\"nDCG@{k}\": ndcg\n",
    "    })\n",
    "    return df\n",
    "\n",
    "pd.set_option('display.precision', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b57c990-e833-4716-978d-184fe5687c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for con_query in [1, 2, 3]:\n",
    "#    for k in [5, 10, 20]:\n",
    "    for k in [10]:\n",
    "        print(f'Resultados para conjunto de query {con_query} e k={k}')\n",
    "        display(compara_metricas(con_query, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8783475-d5f9-4187-9a1c-6d40fcac50ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [5, 10, 20]:\n",
    "    display(compara_metricas_todas_queries(k))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

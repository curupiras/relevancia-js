{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5a6b528",
   "metadata": {},
   "source": [
    "# Teste 3 - Criando embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b39a4f9",
   "metadata": {},
   "source": [
    "## 1. Cria dataframe com 4 conjuntos cada um com 3 frases distintas em inglês. Frases do mesmo conjunto devem ter uma forte relação semântica, enquanto frases em conjuntos diferentes são distantes semanticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd8fce2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conjunto</th>\n",
       "      <th>Frase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tecnologia e Inovação</td>\n",
       "      <td>Advancements in artificial intelligence are tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tecnologia e Inovação</td>\n",
       "      <td>Advancements in neural artificial intelligence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tecnologia e Inovação</td>\n",
       "      <td>Innovative technologies like blockchain are re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mudanças Climáticas e Meio Ambiente</td>\n",
       "      <td>Global warming is leading to more extreme weat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mudanças Climáticas e Meio Ambiente</td>\n",
       "      <td>Deforestation contributes significantly to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mudanças Climáticas e Meio Ambiente</td>\n",
       "      <td>Renewable energy sources are crucial for reduc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Saúde e Bem-estar</td>\n",
       "      <td>Regular exercise is key to maintaining a healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Saúde e Bem-estar</td>\n",
       "      <td>Mental health awareness is becoming increasing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Saúde e Bem-estar</td>\n",
       "      <td>Balanced nutrition is essential for physical a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Viagens e Cultura</td>\n",
       "      <td>Exploring different cultures enriches our unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Viagens e Cultura</td>\n",
       "      <td>Travel restrictions have impacted internationa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Viagens e Cultura</td>\n",
       "      <td>Learning a new language opens up opportunities...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Conjunto  \\\n",
       "0                 Tecnologia e Inovação   \n",
       "1                 Tecnologia e Inovação   \n",
       "2                 Tecnologia e Inovação   \n",
       "3   Mudanças Climáticas e Meio Ambiente   \n",
       "4   Mudanças Climáticas e Meio Ambiente   \n",
       "5   Mudanças Climáticas e Meio Ambiente   \n",
       "6                     Saúde e Bem-estar   \n",
       "7                     Saúde e Bem-estar   \n",
       "8                     Saúde e Bem-estar   \n",
       "9                     Viagens e Cultura   \n",
       "10                    Viagens e Cultura   \n",
       "11                    Viagens e Cultura   \n",
       "\n",
       "                                                Frase  \n",
       "0   Advancements in artificial intelligence are tr...  \n",
       "1   Advancements in neural artificial intelligence...  \n",
       "2   Innovative technologies like blockchain are re...  \n",
       "3   Global warming is leading to more extreme weat...  \n",
       "4   Deforestation contributes significantly to the...  \n",
       "5   Renewable energy sources are crucial for reduc...  \n",
       "6   Regular exercise is key to maintaining a healt...  \n",
       "7   Mental health awareness is becoming increasing...  \n",
       "8   Balanced nutrition is essential for physical a...  \n",
       "9   Exploring different cultures enriches our unde...  \n",
       "10  Travel restrictions have impacted internationa...  \n",
       "11  Learning a new language opens up opportunities...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dados das frases organizados em um dicionário\n",
    "data = {\n",
    "    \"Conjunto\": [\"Tecnologia e Inovação\", \"Tecnologia e Inovação\", \"Tecnologia e Inovação\",\n",
    "                 \"Mudanças Climáticas e Meio Ambiente\", \"Mudanças Climáticas e Meio Ambiente\", \"Mudanças Climáticas e Meio Ambiente\",\n",
    "                 \"Saúde e Bem-estar\", \"Saúde e Bem-estar\", \"Saúde e Bem-estar\",\n",
    "                 \"Viagens e Cultura\", \"Viagens e Cultura\", \"Viagens e Cultura\"],\n",
    "    \"Frase\": [\"Advancements in artificial intelligence are transforming industries.\",\n",
    "              \"The development of quantum computing holds the potential to revolutionize data processing.\",\n",
    "              \"Innovative technologies like blockchain are reshaping financial transactions.\",\n",
    "              \"Global warming is leading to more extreme weather patterns.\",\n",
    "              \"Deforestation contributes significantly to the increase in atmospheric carbon dioxide levels.\",\n",
    "              \"Renewable energy sources are crucial for reducing greenhouse gas emissions.\",\n",
    "              \"Regular exercise is key to maintaining a healthy lifestyle.\",\n",
    "              \"Mental health awareness is becoming increasingly important in society.\",\n",
    "              \"Balanced nutrition is essential for physical and mental well-being.\",\n",
    "              \"Exploring different cultures enriches our understanding of the world.\",\n",
    "              \"Travel restrictions have impacted international tourism significantly.\",\n",
    "              \"Learning a new language opens up opportunities for cultural exchange.\"]\n",
    "}\n",
    "\n",
    "# Criando o DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Exibindo o DataFrame\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a03e01d",
   "metadata": {},
   "source": [
    "## 2. Tokenização do texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9f110dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santosr\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "#Carregando o nokenizador Distilbert\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6efc95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definição da função que realizará a tokenização em lotes\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"Frase\"], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "add861a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 12607, 2015, 1999, 7976, 4454, 2024, 17903, 6088, 1012, 102, 0, 0, 0, 0], [101, 12607, 2015, 1999, 15756, 7976, 4454, 2024, 17903, 6088, 1012, 102, 0, 0, 0], [101, 9525, 6786, 2066, 3796, 24925, 2078, 2024, 24501, 3270, 4691, 3361, 11817, 1012, 102], [101, 3795, 12959, 2003, 2877, 2000, 2062, 6034, 4633, 7060, 1012, 102, 0, 0, 0], [101, 13366, 25794, 16605, 6022, 2000, 1996, 3623, 1999, 12483, 6351, 14384, 3798, 1012, 102], [101, 13918, 2943, 4216, 2024, 10232, 2005, 8161, 16635, 3806, 11768, 1012, 102, 0, 0], [101, 3180, 6912, 2003, 3145, 2000, 8498, 1037, 7965, 9580, 1012, 102, 0, 0, 0], [101, 5177, 2740, 7073, 2003, 3352, 6233, 2590, 1999, 2554, 1012, 102, 0, 0, 0], [101, 12042, 14266, 2003, 6827, 2005, 3558, 1998, 5177, 2092, 1011, 2108, 1012, 102, 0], [101, 11131, 2367, 8578, 4372, 13149, 2229, 2256, 4824, 1997, 1996, 2088, 1012, 102, 0], [101, 3604, 9259, 2031, 19209, 2248, 6813, 6022, 1012, 102, 0, 0, 0, 0, 0], [101, 4083, 1037, 2047, 2653, 7480, 2039, 6695, 2005, 3451, 3863, 1012, 102, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando a função de tokenização aos dados\n",
    "data_encoded = data.copy()\n",
    "tokenized_outputs = tokenize(data_encoded)\n",
    "tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecf6ae86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Conjunto', 'Frase', 'input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Armazenando input_ids e attention_mask em data_encoded\n",
    "data_encoded['input_ids'] = tokenized_outputs['input_ids']\n",
    "data_encoded['attention_mask'] = tokenized_outputs['attention_mask']\n",
    "data_encoded.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56b4b6ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase: Advancements in artificial intelligence are transforming industries., \n",
      "Input IDs: ['[CLS]', 'advancement', '##s', 'in', 'artificial', 'intelligence', 'are', 'transforming', 'industries', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "\n",
      "Frase: Advancements in neural artificial intelligence are transforming industries., \n",
      "Input IDs: ['[CLS]', 'advancement', '##s', 'in', 'neural', 'artificial', 'intelligence', 'are', 'transforming', 'industries', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]']\n",
      "\n",
      "Frase: Innovative technologies like blockchain are reshaping financial transactions., \n",
      "Input IDs: ['[CLS]', 'innovative', 'technologies', 'like', 'block', '##chai', '##n', 'are', 'res', '##ha', '##ping', 'financial', 'transactions', '.', '[SEP]']\n",
      "\n",
      "Frase: Global warming is leading to more extreme weather patterns., \n",
      "Input IDs: ['[CLS]', 'global', 'warming', 'is', 'leading', 'to', 'more', 'extreme', 'weather', 'patterns', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]']\n",
      "\n",
      "Frase: Deforestation contributes significantly to the increase in atmospheric carbon dioxide levels., \n",
      "Input IDs: ['[CLS]', 'def', '##orestation', 'contributes', 'significantly', 'to', 'the', 'increase', 'in', 'atmospheric', 'carbon', 'dioxide', 'levels', '.', '[SEP]']\n",
      "\n",
      "Frase: Renewable energy sources are crucial for reducing greenhouse gas emissions., \n",
      "Input IDs: ['[CLS]', 'renewable', 'energy', 'sources', 'are', 'crucial', 'for', 'reducing', 'greenhouse', 'gas', 'emissions', '.', '[SEP]', '[PAD]', '[PAD]']\n",
      "\n",
      "Frase: Regular exercise is key to maintaining a healthy lifestyle., \n",
      "Input IDs: ['[CLS]', 'regular', 'exercise', 'is', 'key', 'to', 'maintaining', 'a', 'healthy', 'lifestyle', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]']\n",
      "\n",
      "Frase: Mental health awareness is becoming increasingly important in society., \n",
      "Input IDs: ['[CLS]', 'mental', 'health', 'awareness', 'is', 'becoming', 'increasingly', 'important', 'in', 'society', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]']\n",
      "\n",
      "Frase: Balanced nutrition is essential for physical and mental well-being., \n",
      "Input IDs: ['[CLS]', 'balanced', 'nutrition', 'is', 'essential', 'for', 'physical', 'and', 'mental', 'well', '-', 'being', '.', '[SEP]', '[PAD]']\n",
      "\n",
      "Frase: Exploring different cultures enriches our understanding of the world., \n",
      "Input IDs: ['[CLS]', 'exploring', 'different', 'cultures', 'en', '##rich', '##es', 'our', 'understanding', 'of', 'the', 'world', '.', '[SEP]', '[PAD]']\n",
      "\n",
      "Frase: Travel restrictions have impacted international tourism significantly., \n",
      "Input IDs: ['[CLS]', 'travel', 'restrictions', 'have', 'impacted', 'international', 'tourism', 'significantly', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "\n",
      "Frase: Learning a new language opens up opportunities for cultural exchange., \n",
      "Input IDs: ['[CLS]', 'learning', 'a', 'new', 'language', 'opens', 'up', 'opportunities', 'for', 'cultural', 'exchange', '.', '[SEP]', '[PAD]', '[PAD]']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for frase, input_id in zip(data_encoded[\"Frase\"], data_encoded[\"input_ids\"]):\n",
    "    print(f\"Frase: {frase}, \\nInput IDs: {tokenizer.convert_ids_to_tokens(input_id)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4396e168",
   "metadata": {},
   "source": [
    "## 3. Obtenção dos embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abaf2f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel\n",
    "\n",
    "#Carregar modelo distilbert\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "\n",
    "#Caso exista GPU utilize-a, caso contrário use a CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f514a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para extração da última camada oculta (apenas a representação do token [CLS])\n",
    "def extract_hidden_states(batch):\n",
    "    # Place model inputs on the GPU\n",
    "    inputs = {k:v.to(device) for k,v in batch.items() \n",
    "              if k in tokenizer.model_input_names}\n",
    "    # Extract last hidden states\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "    # Return vector for [CLS] token\n",
    "    return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c56790ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforma os input_ids e attention_mask em tensores\n",
    "data_encoded['input_ids'] = torch.tensor(data_encoded['input_ids'])\n",
    "data_encoded['attention_mask'] = torch.tensor(data_encoded['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70daf6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrai a última camada oculta de data_encoded e armazena em hidden_state\n",
    "hidden_state = extract_hidden_states(data_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb3148ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Conjunto': ['Tecnologia e Inovação',\n",
       "  'Tecnologia e Inovação',\n",
       "  'Tecnologia e Inovação',\n",
       "  'Mudanças Climáticas e Meio Ambiente',\n",
       "  'Mudanças Climáticas e Meio Ambiente',\n",
       "  'Mudanças Climáticas e Meio Ambiente',\n",
       "  'Saúde e Bem-estar',\n",
       "  'Saúde e Bem-estar',\n",
       "  'Saúde e Bem-estar',\n",
       "  'Viagens e Cultura',\n",
       "  'Viagens e Cultura',\n",
       "  'Viagens e Cultura'],\n",
       " 'Frase': ['Advancements in artificial intelligence are transforming industries.',\n",
       "  'Advancements in neural artificial intelligence are transforming industries.',\n",
       "  'Innovative technologies like blockchain are reshaping financial transactions.',\n",
       "  'Global warming is leading to more extreme weather patterns.',\n",
       "  'Deforestation contributes significantly to the increase in atmospheric carbon dioxide levels.',\n",
       "  'Renewable energy sources are crucial for reducing greenhouse gas emissions.',\n",
       "  'Regular exercise is key to maintaining a healthy lifestyle.',\n",
       "  'Mental health awareness is becoming increasingly important in society.',\n",
       "  'Balanced nutrition is essential for physical and mental well-being.',\n",
       "  'Exploring different cultures enriches our understanding of the world.',\n",
       "  'Travel restrictions have impacted international tourism significantly.',\n",
       "  'Learning a new language opens up opportunities for cultural exchange.'],\n",
       " 'input_ids': tensor([[  101, 12607,  2015,  1999,  7976,  4454,  2024, 17903,  6088,  1012,\n",
       "            102,     0,     0,     0,     0],\n",
       "         [  101, 12607,  2015,  1999, 15756,  7976,  4454,  2024, 17903,  6088,\n",
       "           1012,   102,     0,     0,     0],\n",
       "         [  101,  9525,  6786,  2066,  3796, 24925,  2078,  2024, 24501,  3270,\n",
       "           4691,  3361, 11817,  1012,   102],\n",
       "         [  101,  3795, 12959,  2003,  2877,  2000,  2062,  6034,  4633,  7060,\n",
       "           1012,   102,     0,     0,     0],\n",
       "         [  101, 13366, 25794, 16605,  6022,  2000,  1996,  3623,  1999, 12483,\n",
       "           6351, 14384,  3798,  1012,   102],\n",
       "         [  101, 13918,  2943,  4216,  2024, 10232,  2005,  8161, 16635,  3806,\n",
       "          11768,  1012,   102,     0,     0],\n",
       "         [  101,  3180,  6912,  2003,  3145,  2000,  8498,  1037,  7965,  9580,\n",
       "           1012,   102,     0,     0,     0],\n",
       "         [  101,  5177,  2740,  7073,  2003,  3352,  6233,  2590,  1999,  2554,\n",
       "           1012,   102,     0,     0,     0],\n",
       "         [  101, 12042, 14266,  2003,  6827,  2005,  3558,  1998,  5177,  2092,\n",
       "           1011,  2108,  1012,   102,     0],\n",
       "         [  101, 11131,  2367,  8578,  4372, 13149,  2229,  2256,  4824,  1997,\n",
       "           1996,  2088,  1012,   102,     0],\n",
       "         [  101,  3604,  9259,  2031, 19209,  2248,  6813,  6022,  1012,   102,\n",
       "              0,     0,     0,     0,     0],\n",
       "         [  101,  4083,  1037,  2047,  2653,  7480,  2039,  6695,  2005,  3451,\n",
       "           3863,  1012,   102,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]]),\n",
       " 'hidden_state': tensor([[-0.2004, -0.2734, -0.2279,  ..., -0.4459,  0.5168, -0.0521],\n",
       "         [-0.2513, -0.2847, -0.1825,  ..., -0.4500,  0.4566, -0.0422],\n",
       "         [-0.3357, -0.2668, -0.2575,  ..., -0.4859,  0.4035, -0.0346],\n",
       "         ...,\n",
       "         [-0.2978, -0.1125, -0.4791,  ..., -0.2100,  0.5411,  0.1071],\n",
       "         [-0.0956,  0.1608, -0.2762,  ..., -0.4289,  0.2689,  0.1371],\n",
       "         [-0.2075, -0.0526, -0.2169,  ..., -0.3315,  0.3009,  0.1008]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transforma hidden_state em tensor\n",
    "data_hidden = data_encoded.copy()\n",
    "data_hidden['hidden_state'] = torch.tensor(hidden_state['hidden_state'])\n",
    "data_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fb3731b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dimensões de data_hidden\n",
    "data_hidden['hidden_state'].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69a13b1",
   "metadata": {},
   "source": [
    "## 4. Cálculo da distância entre os embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7108b806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade por cosseno: 0.9968863725662231\n"
     ]
    }
   ],
   "source": [
    "# Extraindo os embeddings de duas frases\n",
    "embedding1_tensor = data_hidden['hidden_state'][0]\n",
    "embedding2_tensor = data_hidden['hidden_state'][1]\n",
    "\n",
    "# Normalizando os embeddings\n",
    "embedding1_norm = embedding1_tensor / embedding1_tensor.norm()\n",
    "embedding2_norm = embedding2_tensor / embedding2_tensor.norm()\n",
    "\n",
    "# Calculando a similaridade por cosseno\n",
    "cosine_similarity = torch.dot(embedding1_norm, embedding2_norm)\n",
    "\n",
    "print(f\"Similaridade por cosseno: {cosine_similarity.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e50627a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2417172878.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Usar o FAISS para criar banco ve\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Usar o FAISS para criar banco ve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9beeacaa",
   "metadata": {},
   "source": [
    "## 1. Carrega as bases de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc0d625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Pasta com os dados\n",
    "PASTA_DADOS = './dados/'\n",
    "\n",
    "# Pasta com os dados de jurisprudência já tratados\n",
    "PASTA_JURIS_TCU = f'{PASTA_DADOS}outputs/1_tratamento_juris_tcu/'\n",
    "\n",
    "# Pasta onde serão armazenados os resultados desse caderno\n",
    "PASTA_RESULTADO_CADERNO = f'{PASTA_DADOS}outputs/6_gera_embeddings_js/'\n",
    "\n",
    "# Tamanho do lote\n",
    "#QUANTIDADE_DE_ITENS_CARREGADOS = 5\n",
    "\n",
    "# Tamanho do lote\n",
    "SOBRESCREVER_EMBEDDINGS = False\n",
    "\n",
    "# Tamanho do lote\n",
    "TAMANHO_DO_LOTE = 32\n",
    "\n",
    "# Função que carrega os arquivos \n",
    "def carrega_juris_tcu():\n",
    "    doc1 = pd.read_csv(f'{PASTA_JURIS_TCU}doc_tratado_parte_1.csv', sep='|')\n",
    "    doc2 = pd.read_csv(f'{PASTA_JURIS_TCU}doc_tratado_parte_2.csv', sep='|')\n",
    "    doc3 = pd.read_csv(f'{PASTA_JURIS_TCU}doc_tratado_parte_3.csv', sep='|')\n",
    "    doc4 = pd.read_csv(f'{PASTA_JURIS_TCU}doc_tratado_parte_4.csv', sep='|')\n",
    "    doc = pd.concat([doc1, doc2, doc3, doc4], ignore_index=True)\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "865dab47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['KEY', 'NUMACORDAO', 'ANOACORDAO', 'COLEGIADO', 'AREA', 'TEMA', 'SUBTEMA', 'ENUNCIADO', 'EXCERTO', 'NUMSUMULA', 'DATASESSAOFORMATADA', 'AUTORTESE', 'FUNCAOAUTORTESE', 'TIPOPROCESSO', 'TIPORECURSO', 'INDEXACAO', 'INDEXADORESCONSOLIDADOS', 'PARAGRAFOLC', 'REFERENCIALEGAL', 'PUBLICACAOAPRESENTACAO', 'PARADIGMATICO'])\n"
     ]
    }
   ],
   "source": [
    "from formatador import remove_html\n",
    "\n",
    "# Carrega os arquivos para doc\n",
    "doc = carrega_juris_tcu()\n",
    "#doc = doc.head(QUANTIDADE_DE_ITENS_CARREGADOS)\n",
    "\n",
    "#Remove tags do enunciado\n",
    "doc['ENUNCIADO'] = doc['ENUNCIADO'].apply(remove_html)\n",
    "\n",
    "#Transforma dataframe em dicionário\n",
    "doc = doc.to_dict(orient='list')\n",
    "print(doc.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0949465a",
   "metadata": {},
   "source": [
    "## 2. Tokenização do texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad72d7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santosr\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "#Carregando o nokenizador Legal BERTimbau V3\n",
    "model_ckpt = 'rufimelo/Legal-BERTimbau-sts-large-ma-v3'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "399de17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definição da função que realizará a tokenização em lotes\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"ENUNCIADO\"], padding=True, truncation=True, return_tensors='pt', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7821f406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,   200, 22371,  ...,     0,     0,     0],\n",
       "        [  101,   200, 22371,  ...,     0,     0,     0],\n",
       "        [  101,   200, 22371,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,   200, 22371,  ...,     0,     0,     0],\n",
       "        [  101,   200, 22371,  ...,     0,     0,     0],\n",
       "        [  101,   200, 22371,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando a função de tokenização aos dados\n",
    "doc_encoded = doc.copy()\n",
    "tokenized_outputs = tokenize(doc_encoded)\n",
    "tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe3a6bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['KEY', 'NUMACORDAO', 'ANOACORDAO', 'COLEGIADO', 'AREA', 'TEMA', 'SUBTEMA', 'ENUNCIADO', 'EXCERTO', 'NUMSUMULA', 'DATASESSAOFORMATADA', 'AUTORTESE', 'FUNCAOAUTORTESE', 'TIPOPROCESSO', 'TIPORECURSO', 'INDEXACAO', 'INDEXADORESCONSOLIDADOS', 'PARAGRAFOLC', 'REFERENCIALEGAL', 'PUBLICACAOAPRESENTACAO', 'PARADIGMATICO', 'input_ids', 'attention_mask', 'token_type_ids'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Armazenando input_ids, attention_mask e token_type_ids em doc_encoded\n",
    "doc_encoded['input_ids'] = tokenized_outputs['input_ids']\n",
    "doc_encoded['attention_mask'] = tokenized_outputs['attention_mask']\n",
    "doc_encoded['token_type_ids'] = tokenized_outputs['token_type_ids']\n",
    "doc_encoded.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd538c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enunciado: SÚMULA TCU 43 (REVOGADA) : As pensões deferidas antes de 21/10/69, aos dependentes do pessoal, reformado, ou em atividade, da Polícia Militar e do Corpo de Bombeiros, transferido para o Estado da Guanabara, devem ser custeadas pela União, cabendo, porém, ao referido Estado a responsabilidade integral do pagamento decorrente dos reajustamentos posteriores., \n",
      "Input IDs: ['[CLS]', 'S', '##Ú', '##M', '##UL', '##A', 'T', '##C', '##U', '43', '(', 'R', '##E', '##V', '##O', '##GA', '##DA', ')', ':', 'As', 'pens', '##ões', 'defe', '##rida', '##s', 'antes', 'de', '21', '/', '10', '/', '69', ',', 'aos', 'dependentes', 'do', 'pessoal', ',', 'reforma', '##do', ',', 'ou', 'em', 'atividade', ',', 'da', 'Polícia', 'Militar', 'e', 'do', 'Corpo', 'de', 'Bombeiros', ',', 'transferido', 'para', 'o', 'Estado', 'da', 'Guanabara', ',', 'devem', 'ser', 'cus', '##te', '##adas', 'pela', 'União', ',', 'cabe', '##ndo', ',', 'porém', ',', 'ao', 'referido', 'Estado', 'a', 'responsa', '##bilidade', 'integral', 'do', 'pagamento', 'decorre', '##nte', 'dos', 'rea', '##jus', '##tamentos', 'posteriores', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "\n",
      "Enunciado: SÚMULA TCU 99 (REVOGADA) : Não pode ser imputado à conta dos Fundos de Participação (Constituição, art. 25) o percentual compulsório que incide sobre as receitas correntes próprias dos Estados, Municípios, Distrito Federal e Territórios, para a constituição do Programa de Formação do Patrimônio do Servidor Público (PASEP) ., \n",
      "Input IDs: ['[CLS]', 'S', '##Ú', '##M', '##UL', '##A', 'T', '##C', '##U', '99', '(', 'R', '##E', '##V', '##O', '##GA', '##DA', ')', ':', 'Não', 'pode', 'ser', 'imp', '##uta', '##do', 'à', 'conta', 'dos', 'Fundo', '##s', 'de', 'Participa', '##ção', '(', 'Constituição', ',', 'art', '.', '25', ')', 'o', 'percentual', 'compu', '##ls', '##ório', 'que', 'inc', '##ide', 'sobre', 'as', 'receitas', 'correntes', 'próprias', 'dos', 'Estados', ',', 'Município', '##s', ',', 'Distrito', 'Federal', 'e', 'Território', '##s', ',', 'para', 'a', 'constituição', 'do', 'Programa', 'de', 'Formação', 'do', 'Patrimônio', 'do', 'Servi', '##dor', 'Público', '(', 'PA', '##SE', '##P', ')', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "\n",
      "Enunciado: SÚMULA TCU 84 (REVOGADA) : Restabelecer-se-á a entrega das quotas provenientes do Fundo de Participação (Constituição, art. 25) , quando ficar comprovado que a omissão ou irregularidade, que deu motivo à suspensão, não pode ser imputada ao atual administrador e que este já adotou providência no sentido de saná-la ou de evitar a sua reincidência, bem como de apurar, se for o caso, a responsabilidade do seu antecessor., \n",
      "Input IDs: ['[CLS]', 'S', '##Ú', '##M', '##UL', '##A', 'T', '##C', '##U', '84', '(', 'R', '##E', '##V', '##O', '##GA', '##DA', ')', ':', 'Resta', '##belec', '##er', '-', 'se', '-', 'á', 'a', 'entrega', 'das', 'quo', '##tas', 'provenientes', 'do', 'Fundo', 'de', 'Participa', '##ção', '(', 'Constituição', ',', 'art', '.', '25', ')', ',', 'quando', 'ficar', 'compro', '##vado', 'que', 'a', 'om', '##issão', 'ou', 'irregular', '##idade', ',', 'que', 'deu', 'motivo', 'à', 'suspensão', ',', 'não', 'pode', 'ser', 'imp', '##uta', '##da', 'ao', 'atual', 'administrador', 'e', 'que', 'este', 'já', 'adotou', 'provid', '##ência', 'no', 'sentido', 'de', 'san', '##á', '-', 'la', 'ou', 'de', 'evitar', 'a', 'sua', 'rein', '##ci', '##d', '##ência', ',', 'bem', 'como', 'de', 'apura', '##r', ',', 'se', 'for', 'o', 'caso', ',', 'a', 'responsa', '##bilidade', 'do', 'seu', 'antecessor', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verifica se a tokenização foi realizada adequadamente\n",
    "from itertools import islice\n",
    "\n",
    "for enunciado, input_id in islice(zip(doc_encoded[\"ENUNCIADO\"], doc_encoded[\"input_ids\"]), 3):\n",
    "    print(f\"Enunciado: {enunciado}, \\nInput IDs: {tokenizer.convert_ids_to_tokens(input_id)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5513bbb6",
   "metadata": {},
   "source": [
    "## 3. Obtenção dos embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb84c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel\n",
    "\n",
    "# Carrega modelo\n",
    "\n",
    "#Caso exista GPU utilize-a, caso contrário use a CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9f9e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para agregaçção da última camada oculta pela média\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98e238c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para extração da última camada oculta\n",
    "def extract_hidden_states(batch):\n",
    "    # Place model inputs on the GPU\n",
    "    inputs = {k:v.to(device) for k,v in batch.items() \n",
    "              if k in tokenizer.model_input_names}\n",
    "    # Extract last hidden states\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**inputs)\n",
    "    \n",
    "    return batch['KEY'], model_output.last_hidden_state[:,0].cpu().numpy(), mean_pooling(model_output, inputs['attention_mask']).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43ebb7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para dividir dicionário em lotes\n",
    "def dividir_dicionario_em_lotes(dicionario, tamanho_do_lote):\n",
    "    vetor_de_dicionarios = []\n",
    "    max_len = max(len(v) for v in dicionario.values())  # Encontrando o vetor de valores mais longo\n",
    "    \n",
    "    for i in range(0, max_len, tamanho_do_lote):\n",
    "        novo_dicionario = {chave: valores[i:i + tamanho_do_lote] for chave, valores in dicionario.items()}\n",
    "        vetor_de_dicionarios.append(novo_dicionario)\n",
    "    \n",
    "    return vetor_de_dicionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "211010a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Função para reconstruir dicionário a partir de lotes\n",
    "def reconstruir_dicionario_a_partir_de_lotes(vetor_de_dicionarios):\n",
    "    dicionario_reconstruido = {}\n",
    "    \n",
    "    # Inicializando listas vazias para cada chave no primeiro dicionário do vetor\n",
    "    for chave in vetor_de_dicionarios[0].keys():\n",
    "        dicionario_reconstruido[chave] = []\n",
    "    \n",
    "    # Iterando sobre cada dicionário no vetor e concatenando os valores para cada chave\n",
    "    for dicionario_lote in vetor_de_dicionarios:\n",
    "        for chave, valores in dicionario_lote.items():\n",
    "            dicionario_reconstruido[chave].extend(valores)\n",
    "    \n",
    "    # Transforma numpy array em tensor\n",
    "    dicionario_reconstruido['cls_hidden_state'] = torch.tensor(np.array(dicionario_reconstruido['cls_hidden_state']))\n",
    "    dicionario_reconstruido['mean_hidden_state'] = torch.tensor(np.array(dicionario_reconstruido['mean_hidden_state']))\n",
    "    \n",
    "    return dicionario_reconstruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4e3a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/502 [11:33<8:39:44, 63.51s/it]"
     ]
    }
   ],
   "source": [
    "# Processar e salvar embeddings\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Divide doc_encoded em lotes\n",
    "doc_encoded_em_lotes = dividir_dicionario_em_lotes(doc_encoded, TAMANHO_DO_LOTE)\n",
    "\n",
    "# Processa e salva embeddings\n",
    "for i, dicionario in enumerate(tqdm(doc_encoded_em_lotes), start=1):\n",
    "    \n",
    "    caminho_arquivo = f'{PASTA_RESULTADO_CADERNO}embeddings_js_{i}.pickle'\n",
    "    if  not SOBRESCREVER_EMBEDDINGS and os.path.exists(caminho_arquivo):\n",
    "        continue\n",
    "\n",
    "    key, cls_hidden_state, mean_hidden_state = extract_hidden_states(dicionario)\n",
    "    \n",
    "    # Cria estrutura que será salva em arquivo\n",
    "    embeddings_js = {\n",
    "        'key': key,\n",
    "        'cls_hidden_state': cls_hidden_state,\n",
    "        'mean_hidden_state': mean_hidden_state\n",
    "    }\n",
    "    \n",
    "    # Gravando lote em um arquivo .pickle\n",
    "    with open(caminho_arquivo, 'wb') as arquivo_pickle:\n",
    "        pickle.dump(embeddings_js, arquivo_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6796671",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario['input_ids'].size()\n",
    "#dicionario['attention_mask']\n",
    "#dicionario['token_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e484a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_encoded_em_lotes[0]['KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01feab6",
   "metadata": {},
   "source": [
    "## 4. Cálculo da distância entre os embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2667ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para restaurar embeddings dos arquivos pickle\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def restaurar_doc_encoded_de_pickle(pasta_resultado_caderno):\n",
    "    # Lista para armazenar os dicionários lidos dos arquivos .pickle\n",
    "    doc_encoded_restaurado = []\n",
    "\n",
    "    # Listando todos os arquivos .pickle no diretório especificado\n",
    "    arquivos_pickle = [arq for arq in os.listdir(pasta_resultado_caderno) if arq.endswith('.pickle')]\n",
    "\n",
    "    # Ordenando os arquivos pelo número (assumindo que os nomes dos arquivos seguem o padrão embeddings_js_X.pickle)\n",
    "    arquivos_pickle.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "\n",
    "    # Lendo cada arquivo .pickle e restaurando o dicionário\n",
    "    for nome_arquivo in arquivos_pickle:\n",
    "        caminho_arquivo = os.path.join(pasta_resultado_caderno, nome_arquivo)\n",
    "        with open(caminho_arquivo, 'rb') as arquivo_pickle:\n",
    "            dicionario_restaurado = pickle.load(arquivo_pickle)\n",
    "            doc_encoded_restaurado.append(dicionario_restaurado)\n",
    "\n",
    "    return reconstruir_dicionario_a_partir_de_lotes(doc_encoded_restaurado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb7a352",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_encoded_restaurado = restaurar_doc_encoded_de_pickle(PASTA_RESULTADO_CADERNO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16c12dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "doc_hidden = doc_encoded.copy()\n",
    "doc_hidden['cls_hidden_state'] = doc_encoded_restaurado['cls_hidden_state']\n",
    "doc_hidden['mean_hidden_state'] = doc_encoded_restaurado['mean_hidden_state']\n",
    "print(f\"cls_hidden_state: {doc_hidden['cls_hidden_state'].size()}\\n\")\n",
    "print(f\"mean_hidden_state: {doc_hidden['mean_hidden_state'].size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb93967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraindo os embeddings de duas frases\n",
    "embedding1_tensor = doc_hidden['mean_hidden_state'][0]\n",
    "embedding2_tensor = doc_hidden['mean_hidden_state'][4]\n",
    "\n",
    "# Normalizando os embeddings\n",
    "embedding1_norm = embedding1_tensor / embedding1_tensor.norm()\n",
    "embedding2_norm = embedding2_tensor / embedding2_tensor.norm()\n",
    "\n",
    "# Calculando a similaridade por cosseno\n",
    "cosine_similarity = torch.dot(embedding1_norm, embedding2_norm)\n",
    "\n",
    "print(f\"Similaridade por cosseno: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da3a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_encoded_restaurado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c33056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc_hidden['ENUNCIADO'][0])\n",
    "print(doc_hidden['ENUNCIADO'][1])\n",
    "print(doc_hidden['ENUNCIADO'][4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

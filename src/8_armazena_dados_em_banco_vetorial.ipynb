{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f68a4b",
   "metadata": {},
   "source": [
    "## 1. Carregando os dados dos embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e70013b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para restaurar embeddings dos documentos de arquivos pickle\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "###############################################################################\n",
    "# Modelos\n",
    "MODELO = 'rufimelo/Legal-BERTimbau-sts-large-ma-v3'\n",
    "MAX_SEQ_LENGTH = 512\n",
    "\n",
    "#MODELO = 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2'\n",
    "#MAX_SEQ_LENGTH = 128\n",
    "###############################################################################\n",
    "\n",
    "CAMINHO_MODELO = MODELO.split(\"/\")[-1]\n",
    "\n",
    "# Pasta com os dados\n",
    "PASTA_DADOS = './dados/'\n",
    "\n",
    "# Pasta com os embeddings dos documentos\n",
    "PASTA_DOCUMENTOS = f'{PASTA_DADOS}outputs/6_gera_embeddings_js/{CAMINHO_MODELO}/'                   \n",
    "\n",
    "# Pasta com os embeddings das queries\n",
    "PASTA_QUERIES = f'{PASTA_DADOS}outputs/7_gera_embeddings_termos/{CAMINHO_MODELO}/'\n",
    "\n",
    "# Pasta com os resultados do caderno\n",
    "PASTA_RESULTADO_CADERNO = f'{PASTA_DADOS}outputs/8_armazena_dados_em_banco_vetorial/{CAMINHO_MODELO}/'\n",
    "\n",
    "# Seleciona o tipo de camada oculta\n",
    "TIPO_CAMADA_OCULTA = 'mean_hidden_state'\n",
    "#TIPO_CAMADA_OCULTA = 'cls_hidden_state'\n",
    "\n",
    "# Função para reconstruir dicionário a partir de lotes\n",
    "def reconstruir_dicionario_a_partir_de_lotes(vetor_de_dicionarios):\n",
    "    dicionario_reconstruido = {}\n",
    "    \n",
    "    # Inicializando listas vazias para cada chave no primeiro dicionário do vetor\n",
    "    for chave in vetor_de_dicionarios[0].keys():\n",
    "        dicionario_reconstruido[chave] = []\n",
    "    \n",
    "    # Iterando sobre cada dicionário no vetor e concatenando os valores para cada chave\n",
    "    for dicionario_lote in vetor_de_dicionarios:\n",
    "        for chave, valores in dicionario_lote.items():\n",
    "            dicionario_reconstruido[chave].extend(valores)\n",
    "    \n",
    "    # Transforma numpy array em tensor\n",
    "    #dicionario_reconstruido['cls_hidden_state'] = torch.tensor(np.array(dicionario_reconstruido['cls_hidden_state']))\n",
    "    #dicionario_reconstruido['mean_hidden_state'] = torch.tensor(np.array(dicionario_reconstruido['mean_hidden_state']))\n",
    "    \n",
    "    dicionario_reconstruido['cls_hidden_state'] = np.array(dicionario_reconstruido['cls_hidden_state'])\n",
    "    dicionario_reconstruido['mean_hidden_state'] = np.array(dicionario_reconstruido['mean_hidden_state'])\n",
    "    \n",
    "    return dicionario_reconstruido\n",
    "\n",
    "# Função para restaurar embeddings dos documentos de arquivos pickle\n",
    "def restaurar_doc_encoded_de_pickle(pasta_resultado_caderno):\n",
    "    # Lista para armazenar os dicionários lidos dos arquivos .pickle\n",
    "    doc_encoded_restaurado = []\n",
    "\n",
    "    # Listando todos os arquivos .pickle no diretório especificado\n",
    "    arquivos_pickle = [arq for arq in os.listdir(pasta_resultado_caderno) if arq.endswith('.pickle')]\n",
    "\n",
    "    # Ordenando os arquivos pelo número (assumindo que os nomes dos arquivos seguem o padrão embeddings_js_X.pickle)\n",
    "    arquivos_pickle.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "\n",
    "    # Lendo cada arquivo .pickle e restaurando o dicionário\n",
    "    for nome_arquivo in arquivos_pickle:\n",
    "        caminho_arquivo = os.path.join(pasta_resultado_caderno, nome_arquivo)\n",
    "        with open(caminho_arquivo, 'rb') as arquivo_pickle:\n",
    "            dicionario_restaurado = pickle.load(arquivo_pickle)\n",
    "            doc_encoded_restaurado.append(dicionario_restaurado)\n",
    "\n",
    "    return reconstruir_dicionario_a_partir_de_lotes(doc_encoded_restaurado)\n",
    "\n",
    "# Função para restaurar embeddings das queries de arquivos pickle\n",
    "def restaurar_query_encoded_de_pickle(pasta_resultado_caderno):\n",
    "    # Lista para armazenar os dicionários lidos dos arquivos .pickle\n",
    "    query_encoded_restaurado = []\n",
    "\n",
    "    # Listando todos os arquivos .pickle no diretório especificado\n",
    "    arquivos_pickle = [arq for arq in os.listdir(pasta_resultado_caderno) if arq.endswith('.pickle')]\n",
    "\n",
    "    # Ordenando os arquivos pelo número (assumindo que os nomes dos arquivos seguem o padrão embeddings_query_X.pickle)\n",
    "    arquivos_pickle.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "\n",
    "    # Lendo cada arquivo .pickle e restaurando o dicionário\n",
    "    for nome_arquivo in arquivos_pickle:\n",
    "        caminho_arquivo = os.path.join(pasta_resultado_caderno, nome_arquivo)\n",
    "        with open(caminho_arquivo, 'rb') as arquivo_pickle:\n",
    "            dicionario_restaurado = pickle.load(arquivo_pickle)\n",
    "            query_encoded_restaurado.append(dicionario_restaurado)\n",
    "\n",
    "    return reconstruir_dicionario_a_partir_de_lotes(query_encoded_restaurado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4375c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega dados de queries\n",
    "query_encoded_restaurado = restaurar_query_encoded_de_pickle(PASTA_QUERIES)\n",
    "xq = query_encoded_restaurado[TIPO_CAMADA_OCULTA]\n",
    "\n",
    "# Carrega dados de documentos\n",
    "doc_encoded_restaurado = restaurar_doc_encoded_de_pickle(PASTA_DOCUMENTOS)\n",
    "xb = doc_encoded_restaurado[TIPO_CAMADA_OCULTA]\n",
    "id_list = [item.replace('JURISPRUDENCIA-SELECIONADA-LEGADA-', '') for item in doc_encoded_restaurado['key']]\n",
    "id_list = [item.replace('JURISPRUDENCIA-SELECIONADA-', '') for item in id_list]\n",
    "id_list = list(map(int, id_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d8c356",
   "metadata": {},
   "source": [
    "## 2. Construindo um índice e adicionando os vetores a ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "105602b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "16045\n"
     ]
    }
   ],
   "source": [
    "import faiss                   # make faiss available\n",
    "\n",
    "#Cria índice com mapeamento de ID (IndexIDMap)\n",
    "index = faiss.IndexIDMap(faiss.IndexFlatL2(len(xb[0])))\n",
    "\n",
    "# Verifica se o índice já está treinado\n",
    "print(index.is_trained)\n",
    "\n",
    "# Adiciona os vetores ao índice do banco de dados\n",
    "index.add_with_ids(xb, id_list)\n",
    "\n",
    "# Verifica o número de vetores indexados\n",
    "print(index.ntotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5261db38",
   "metadata": {},
   "source": [
    "## 3. Buscando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a682a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k é o número de vetores que serão retornados na busca\n",
    "k = 50\n",
    "\n",
    "# teste de sanidade do banco\n",
    "#D, I = index.search(xb[:5], k) # sanity check\n",
    "#print(I)\n",
    "#print(D)\n",
    "\n",
    "# busca propriamente dita\n",
    "D, I = index.search(xq, k)     # actual search\n",
    "\n",
    "# Gravando lote em um arquivo .pickle\n",
    "caminho_arquivo = f'{PASTA_RESULTADO_CADERNO}{CAMINHO_MODELO}_{TIPO_CAMADA_OCULTA}_resultado_query.pickle'\n",
    "with open(caminho_arquivo, 'wb') as arquivo_pickle:\n",
    "    pickle.dump(I, arquivo_pickle)\n",
    "\n",
    "# I é uma matriz inteira de tamanho nq x k, onde a linha i contém os IDs dos k vizinhos do vetor de consulta i,\n",
    "# ordenados por distância crescente\n",
    "\n",
    "# D é uma matriz de ponto flutuante nq x k com as distâncias quadráticas correspondentes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
